In the same way that that it's very counterintuitive that you would be able,  to get an LLM to perform better by using like kind language or telling you're,  going to tip it, I think it also is counterintuitive to people that they,  need to think about assumptions being made when when AI is talking to AI. I,  paradigm shifts that have been yet to be found that I think you and I can find.
or that might exist in the AI security space as well. Yeah yeah yeah 100% and so,  what I'm trying to figure out is like if you take something like SPQA what does,  that actually look like as companies? Right. Like for example I just wrote a,  paid blog post for AT&T. Nice. And like Angela and that person,  person we know, coordinated the whole conversation or whatever. And then I'm just like, okay,
what do they want me to write about? Because what I told them is I'm going to write about,  what I want to write about, right? I'm going to try to make it match somehow to a company,  that you have, sure. Or to something that you have. In the case of AT&T, they were all,  about the conduits, like the connective tissue that's going to be required. Yeah. So I basically,  wrote about continuous AI. And the fact that if you need context to be constantly updated, and all these contexts is being updated constantly, questions are being asked constantly, basically.
SPQA stuff. Yes. You need so much API infrastructure, you need a lot of stuff needs to be real time, you need storage to be super fast. Yes. So it's like, that's a whole space. Yeah, basically, you almost need like, like, we could probably riff on or invent or think of a bunch of.  sub subcategories of long term memory. Yeah, which you just,  call? Which part is contact state? Yeah, yeah, you just.
call us right? It's almost like, for SPQA, there's like an entire,  tree of different companies and niches within state. Yeah. Because it's like, how do you manage that? How do you update,  state? How do you get state across an industry? How do you,  get state out of rack? How do you get? How do you you know, how much do you add to the context? How does the AI know,  when to pull it? Basically, there's almost an entire sub,  industry within state. Yep. Yeah, yeah, absolutely. And then I guess P would be kind of be,  similar. You would need more consulting and intelligence, I.
guess, for P for like a problem. Policy policy, like what is the company about? What are they,  trying to do? So that I feel like it requires more,  intelligence. And also the questions and the actions also,  require a lot more thoughtful. Right. Um, but, and then, and then if you go into like security, like protecting the AI itself, the prompt, uh, stuff, that's a whole set of companies, although, you know what, dude,
I'm starting to think that I almost feel like nobody fucking cares and nobody should care,  because the use cases of like when it's actually going to be super bad, aren't going to be,  very common. So I've been thinking a lot about that. I feel like initially I thought it was going to be a big deal and then I thought, oh, this,  is going to get solved. But now I'm back to thinking that it's actually going to be a big deal, mostly because, uh, I think that the invisible prompt injection, dude, that was so good.
Well, here's the thing. As other models have the emergent properties, the GPT four already had, they're all going,  to be vulnerable too. So it has to be patched in every system or at every LLM provider. Like like, like I think. So, everyone who is now setting up 400B as a service is going to have to re-patch it. Like OpenAI has already patched it. But like, Claude kind of sort of understands it and they haven't really patched it, but,  it doesn't really work reliably. But whatever the next version of Claude is, I think it could potentially regress to where.
it's more effective. I think what happened was, OpenAI, there's only like two articles online about these,  invisible unit code tags. One's in Wikipedia. I think OpenAI heavily weighted Wikipedia, and that's also why it sounds so robotic. I think Anthropic heavily weighted like RLHF. And that's why Opus talks so much more human-like. And so, my theory is the reason why it's not good at invisible prompt injection is because,  the weight that the training from Wikipedia has had on its understanding and reasoning.
for the world is less than OpenAI's models. But anyway, I think that eventually, there are going to be emergent good models. that understand Invisible Prompt Injection,  and they're not going to get patched,  because they have to be patched at the,  provider layer, because you need to,  drop those tokens. Like the Invisible Prompt Injection tokens, the Invisible Unicode Tags. And so, anyway, so I think Invisible Prompt Injection,  is going to resurface. But anyways, my whole point,  is that I think for any Prompt Injection,  issues,
it has to be fixed by every provider. There's not going to be like a one-click install. So it's going to be basically like WAFs,  and it's going to be like.  sanitization,  frameworks. And all of those,  things right now are very disparate and that's why,  you still have XSS on like every website. Like you can design a system that's not vulnerable,  to XSS, but if you're not careful, as soon,  as you add a new webpage, it's like, now it's vulnerable. I worry that that's going to be, that's my first,  Cybertruck I've ever seen in person. I worry, like, so,  anyways, that's just some counterpoints to.
you thinking that it like, to your last statement,  there. I don't know if either one of us heard me right. I have no clue, but that's where my thing has been. there's going to be resurgence is and like some will be bad and,  we'll be like for page news or whatever. Yeah. But to me, it's,  the same as like, fraud and banking, right? All this,  background noise, we just put up with it, right? Well, everyone,  just like, yeah, I guess that happens. And then they'll just,  be, they'll be paid. They'll be training things that basically.
clean this up and all the models will run them afterwards. There's,  like, you got to do this, you know, you'll get prompt,  injected. But the amount of business coming out of the new,  model will be billions of dollars or trillions of dollars. So it's like, if a bunch of people get hacked, right, nobody cares. Nobody cares. Same for the banking industry. It's,  like banks are so valuable, that the risk of fraud and credit,  card fraud and all that is not even comparable to the value and,  the utility that humanity gets out of banks. So it may be the.
same with prompt injection issues. They're going to be,  rare, they're going to require very specific payload. So it's,  going to be highly targeted attacks. It's not going to be,  affect 99.9% of consumers, so no one's really going to care. Well, and also, if it is big, like, everyone will roll out a patch. Right. And like, it'll just be, and two weeks later, it'll just be like a memory, oh, you remember,  that thing? Right. And so, this is why I've pivoted so hard away from very specific technical things, because.
I feel like the bigger things that are happening, that's where I want to be. Yeah. Which is building. Mm-hmm. Making things. Yeah. Because I don't want to get, like, obsessed with the minutiae, because then I'll wake,  up two and a half years later, and I'll be like, what did I just do? Right. It pains me a little bit, but that's honestly one reason why I've been a little bit less,  into bug bounty. Yeah. Because I just think that it feels, I mean, do you know the ladders of wealth creation? Like ladder one, ladder two, you probably do know these.
Ladder one is like working for someone else.
ASM plus pen testing, but anyways, he's a top hacker with hacker one, but he also works,  at match group as like one of their lead, uh, red team people. But um, I was just talking with him and he was like, dude, you should be a VC scout. Basically VCs don't understand the technical know how about, so they have, so they have,  you kind of scouted out and yeah, they're like vetting, right? Yeah. It's like, does this idea actually have merit? Cause they can tell you whether or not. founder's a good founder, but they can't tell you whether or not the product is a good idea,
especially when it comes to deep security products, right? Okay, so that is a great example of the thing that I'm talking about. I want that to be a product. BC Scouting as a service. We should call this BC Scouting as a service. Well, so think about this. Think about collecting,  context on the company. So you do profiles on the founders. You describe the space,  that they're in. Dude, VCs would pay so much for this product. Oh, absolutely. Sorry, I still want to hear your whole idea, but just like my mind jumps to like, holy crap,
they would pay so much money for this. Absolutely. So dude, like we could hack this up today. We should build this. Yeah. Like literally today we can hack this up. It's like, here are the different components. We'll write it up on the whiteboard. We should definitely do this. Yeah, we should whiteboard it out and then just see how much we,  can build with Opus. I bet it would be able to do a very, man, do you think that Opus, I guess they don't have a really great vision model. I guess we,  I wonder how much context GPT Vision could pull out of a picture of a founder, like well.
dressed or like that article that you put in the blog, it could determine someone's,  religious beliefs based on the shape of their head, can you determine someone's success,  by the facial expression, like maybe you can, who knows. I tell you what, it's going to be a little bit of dark arts though because it might come,  back and just be like. Oh it might be racist for sure. It'll just be like, yeah, both founders are Jewish so this is probably, you probably want,  to get in on this one. Right, they're Mormon, they're conscientious, they're going to do great.
How do I open this door? Yeah. Dude, yeah, we should whiteboard this out. That is like very, very, a very, very lucrative idea. Yeah, This is your old Mexican go-to? Yeah, it is. Is your partner's name Sam, you said? You said Sam, that points in. Hi, what's your name?eah, y
Hi. Um, just Chu. Just Chu? Alrighty. How are you guys doing today? Not too bad. Good. Um, she's meeting up with some friends to eat. Do you mind if we just move this table a little bit here?
It's too close to the party. Sure, sure, it's fine. There you go. Your waitress will be with you shortly. Thank you. I noticed your doorbell announced that it was recording me. Yeah, yeah. Is that a California law? Mine doesn't do that. No, that's Ring. I did not love the recent security breach or whatever that happened like three months ago. But I was like, well, at least this will secure up my system.
Because I had already bought a bunch of cameras and a doorbell. And it had been sitting in my garage for like two years. I had just not set it up. And then they had that massive security issue. And I was like, okay, they probably shored up most of these vulnerabilities now. So then I installed them all. So you know what my philosophy is for all of this now? So I only go with giant companies. Right. Because I know they have a giant security team. Yes. And hundreds of millions of dollars to foreign security. Of course. So I'm just like, everyone's hacked. Yes. The question is, who has the money to fix it?
Right. Because they have so much PR. Right. So I'm just like, yeah, stay with Apple, Google, Microsoft, Amazon. It's kind of sad, but I feel the same way. Actually, I put that in my CISO guide or whatever. I don't know if you read it. Actually, I put that in my CISO guide or whatever.
It's like, one, how much do they care, how much are they worried about upsetting their,  base? Two, how much money do they have to clean it up? Well how much skin do they have in the game? A start-up that's not even making profit doesn't care if they get killed by security incident, whereas Amazon shareholders care deeply about whether they get screwed up by security incident, right? Yup. What's your go-to here? Um, if I'm eating light, I get chicken tacos. If I'm eating heavy, I get two chicken enchiladas, but today I'm going to go light because we still got a whole day ahead of us.
Do they have al pastor? I don't know. Oh, they do, yeah. Probably. Yeah, you should... What is that? Try that sometime. It's basically pork that's cooked with pineapples and a ton of seasoning. So it ends up being very flavorful. Very nice.
That's basically our family's favorite... What's a genre of food called? There's a word for that. A genre of food, like a category of food, or like a... What are they called? Style? Yeah. What is it called? Like Mexican food, Japanese food. What are all those called?
Categories? There's a word for like style or genre or category but it's for food. I'm not sure I've ever heard of it. But yeah, Mexican is probably our favorite style of food. There's two within like a half mile or a half that we go to. Our kids are obsessed with queso. Every time we go we have to get them a big old bowl of queso. There's no queso out here. Me and Susan go back. You're joking. We go back to the south. I got her in Georgia by the way.
Nice. So that's our favorite Mexican food is actually the south. Oh yeah. It's so good. And out here. They don't offer queso? There's no queso anywhere. That's crazy. So if we just did a queso place, we would just make so much money. Wow. Wow. Wow. Why they don't offer cheese there? Dude, we forced a Mexican restaurant to try to make this queso one time. They microwaved some cheese. It was like square but melting. They were like, is it good? I was like, no, not as good.
No, it's a travesty. Let me take notes or I'm going to forget. We're on a whiteboard VC, or yeah, VC scout as a service. Oh yeah, I also want a whiteboard. SBQA subcategories. Like just like the market segment. Like if you could market segment state down to like just different subcategories.
The actions are probably the value that you deliver that like people actually care about. Yep. Like the SB, like the, yeah, the SBQ is more like, it's a necessity, it's a necessity, whereas the A is what people care about. It's the dream you're selling. Yep. Yeah.
So what do you think about Salmon? Like, I feel like I was like super pro team Sam and now Yassin on Twitter is like convincing,  me that he's the Antichrist. I don't actually believe that, but I also kind of do get like a little bit of a weird,  vibe from him. I do too. I don't know why. Very, very slight. Yeah. Um. Do you think that the power is just going to his head just a little bit and that's what,  we're, that's what we're sensing or what? I don't know. I don't know. I don't know. I don't know. I don't know.
I think the power is probably going to his head, yes. I do believe that his heart is in the right place. Yeah, yeah. But I'm worried that the signal that I'm getting is likely to only get stronger. Right. Yeah. And especially when government starts steering attention towards him. Right. Well, so it's especially bad because I think the world's about to crash. Right. With the separation of the K. Like people like us, we're just going to thrive and the rest of everyone...
So the government's going to be like, hey listen, we need UBI. Right. And Sam's like, I've been setting up UBI the whole time. Right, just go scan your eyeball and now we'll do crypto UBI. We got crypto going. Yeah. So pretty soon we're getting pretty close to like some revelation shit. Right. Where it's like you get your number and you get your shit. Right. And I'm like, okay, that's a little bit spooky. And then... The problem is, if someone like him goes evil, it goes bad fast.
Yeah, opening has a lot of power right now. Um, I'm super excited about Lama, though. Dude, Lama 3 is so fun. It runs so smooth on my M3. 70B? I mean, that is really good. I've been running all sorts of Fabric stuff with it. Yeah. It's getting back the same results almost as GPT-4 replied. Right. Yeah, I mean like- The long-term reasoning is not as good, but besides that, it's just as good. I even like it's speech style better than opening Asmodus.
Really? It sounds just more natural. Yeah. Like, it sounds more similar to the Claude static. Gotcha. Yeah. Yeah. Yeah, I... I really believe he is trying to do what he says. How are you? Good, how are you? I'm sorry. I'm sorry. What are we making you to drink today? Diet Coke. I'll do a water. Yeah, I think so.
Yeah, I'm going to get two chicken tacos. Crispy or soft? Crispy. Rice and beans? No rice and beans. Can I get a side of jalapenos,  and a side of sour cream? Here you go. I'm going to do three tacos al pastor,  a la carte.
So, first of all, I think he knows,  that... I love the fact that he says AGI is the goal. He's very clear about that. He has been for like three or four years. So, he's like... He also knows it's going to...
I've been a little bit put off by how slippery he's been in some of his answers, if you've,  noticed this. It's PR coaching, but he's doing this thing where he's like, yeah, I just don't think,  GPT-4 is that good. He's trying to be self-deprecating, but at the same time, he's like, his whole body language.
has this vibe on it. That feels the most cagey to me. And he's done some other stuff in some previous interviews where I heard it and I was like, oh wow, that's amazing PR. So he was saying things like, so one of their big narratives is release often, so that there's,  no surprises. Which I think is good, but it's also good PR. Because if he knows this big thing is about to happen, he could just be like, hey look,
I'm as surprised as you are, and I've just been releasing the whole time along. And it seems like they crush other people's releases pretty frequently. Oh yeah. Like they release right after other people release stuff, or right before, it seems like,  they definitely are perfectly playing their hand when it comes to downplaying other people's,  releases. Yeah. Yeah, I'm definitely getting a vibe from him. I know he's world building, no question. The question is what world?
Got it. And that's a little scary to just watch someone who's like, so adeptly world-building, but,  I think I know, I do not think he's lying when he says, I want to build a world of abundance,  where people can be happier. Do you think there was some shady stuff that happened with the board collapse? I mean it was shady, but I don't think in like a... You don't think like a ton of people were mistrusting of him?
No. No. From the inside stuff that I know, I think, um, you had some people freaking out about,  X-Rest. Yes. And they got Ilya to gang up. Yeah. Cool. That was the vibe I got too. But with the latest potential mistrust of Sam, I didn't know if it was like... Oh, someone else? Someone else was seeing the same thing and they thought he was dangerous? Well, I just... Yeah. I just worry that, um, I feel like the biggest concern is like, Sam has so much power.
If he's good at being dishonest or manipulating people, and like that's now what we're getting,  the vibe of in some of these discussions, it's like, was a little bit of that manipulation,  and lying part of what caused that board call, because they did, but they basically did say,  they felt like he wasn't listening, yeah, wasn't listening, basically, so it's just,  interesting. Super interesting. I'm glad that he has rivals in Zuckerberg, and even the fact that like Opus came out.
was so good, makes me feel a lot better about the rivals in the space. Me too. They're not just crushing everyone outright anymore, which I mean, maybe they are internally,  and they just don't want to release it because it's too good. Did you see, like, I retweeted it today, this morning, so you probably haven't seen it. Somebody took Wama70b and just duplicated all the layers with merch. It's way better. And they did no training or classes. Oh, I did see that. They just made it twice as deep. I did see that. It was like a 120. Yes. How does that...
I don't understand that, but let's just say that it's true. Could OpenAI just double the layers of G54 and now it's just like way smarter? Dude, I've been telling my friend at OpenAI about this. So what I've been telling him, and he's not believing me, is that there are hacks, a million,  hacks. Yeah, that we've undiscovered. It's slack in the rope. The rope is like coiled. It's not tight whatsoever. So he's like, no, all the gains are going to come from the increased hardware.
And I'm like, dude, I'm telling you right now, the hardware is going to take this up, guaranteed. But, oh, for example, Brock, that is slack in the rope. Oh yeah. I mean, that thing is huge, way better, way different. 5X or something? Yeah. And I mean... In agents, that's like infeasible to completely feasible. Like, when you're an actor with a website, and it has to do API calls from the back end, it gets slow. Like, I've dealt with this at work in the chat while we're building, right? We're making GraphQL calls to our API to get data back and then responding.
And we still want our response time to be less than 10 seconds. And there's LLMs that are doing the planning and the API translation and all that, right? And we're still able to start a response in less than 10 seconds. With Garak? Dude, we could do... Instantaneous. Well, it would be instantaneous. And we could also make 10 times the calls. We could be hitting lots of other APIs. We could be rewriting our queries multiple times and getting the most accurate one. We could be pulling back way more data and processing it faster. Yep. Like, it's an enabler. Yeah. So, that's slack in the road.
Right. Adding layers might be slack in the road. Right. And how many other things are about to be discovered? Well, I think assumptions made could be slack in the road. Think about this. Imagine if you had all the training data, all of the reinforced... Not obviously the internet training data, but imagine all the chat history that OpenAI has,  when they train GPT-4 based on GPT-3-5, right? There had to have been volumes and volumes of training that occurred based on like user,  upvotes and downvotes, right? Like all of the good user upvote conversations went into that training. What if also in that training, what if from the very get-go they had baked in assumptions.
made and exposed that to users in some way where the users could say like, no I don't,  like that it made this assumption, I do like that it made that assumption. Now imagine that that was metadata that was on all of those condos. Now when the new model is trained, it knows which assumptions to make and which ones to,  not make and ask the user about as a part of its world view, the same way as humans,  we know. How much more would that improve the model? I bet it would improve it by a lot. And so yeah, I think there is like lots of little small nuanced things that like you.
just said that are slacking the road. Anyway, so keep going. Sorry, so you were telling me about this. Yeah, I'm just... Yeah, he was skeptical. I think, especially with all these people playing in open source, that's where most of the experimentations are going to happen, at the fastest turnaround,  time. So I think I put it somewhere recently, I think the open source models are going to,  start jumping over Anthropic and GPT-4, well, between their releases. The problem is their.
releases will be so big, so you'll have these mini hops, it gets to the middle, and then,  boom, way ahead. But humans only need so much processing for most things, so at some point,  we're talking about three, essentially three local, as good as whatever, GPT-7. Right, we're close to that. And how much do you need GPT-7 versus GPT-4, if I'm asking what the weather is?
Thank you. The technology isn't that advanced, like the fact that Andre has basically rewritten all,  this in C in like two weeks, in like 3,000 lines of code, like I think that just that.
project, LLM.C, is going to catapult so much innovation, because all those little hacks,  you're talking about are now really feasible for people to see. Like I think honestly Opus, if you gave it the right prompt, could find some of those,  hacks in LLM.C, because it can see the whole context, and it understands what all that,  code's doing. It can see and recommend those little hacks. Dude, I just did a whole diatribe about this, and I don't remember where I did it. Maybe it was a video. called out your thing. I said, basically, damn, I don't remember where that was. Doesn't.
really matter. But I was like, your idea initially of like all these testing parties. Yeah. So,  it's like this engine of, you have the idea, you do the testing, and it's just round and,  round. Yeah. Just imagine a whole bunch of rock and llama floor, and they just grind,  it constantly. Right. How much have I told you about substrate? Not at all. So this is,  like, this is my life project. This is like the unifying theory. Helios? No. This is like.
the new thing. Or Talos? Nope. Nope. Nope. It's new. Completely new. I brought cards. This will take some time. Okay. It's basically a unified architecture for everything. So I want to talk about substrate and I also want to talk about substrate and get any of,  this. Yes sir.
Oh yeah, I want to tell you about my idea of higher temperature. Okay. Okay. Oh man, I also want to push this back too. I also want to talk to you about monetization ideas for my brand. Okay, let's call that Joseph Brand Combo. Yeah, I have a reminder so we're good. You want to tell me about substrate or do you want me to talk about temperature?
No, temperature. So, I still think basically that we're not bounded by human intelligence with AI output. I know you believe this too. So. So. So. It's kind of like the innovation engine all over again, but I'm wondering if we could,  automate it. Basically, I think higher temperature output, and you slowly ratchet the temperature up.
as you're, like let's say you're opening up, if they were to do something where they slowly,  ratchet temperature up and then basically use their human reinforcement of thumbs up,  and thumbs down. That higher temperature will slowly find nuances and breakthroughs in industries, even if it's,  just slightly better reasoning. I mean, if you have an LLM that can actually detect when a higher temperature answer was,  like actually a lot better versus a lot worse, then you can put that in a training loop.
Anyways, I feel like it would work. That is the thing I talked about in the podcast where I mentioned you. Alright. There's no Einstein. No Einstein. Here's how I pitched it, you teach it what Einstein had access to, the current physical.
physics, the books he was reading, his contemporaries, and then general relativity. You give it multiple examples of going from trig, this is what Newton thought physics,  was, this is what calculus was, and then you say look, these nine things are an example,  of a step jump in new thinking. Here's the word state.
I feel like there's just no doubt if you did that for every industry, lots of them will,  be real. And even if they didn't get it right, it would inspire humans. The real humans are going to look at it and go, that's a better way. That would work. That might work. 100%. Let's do that, but slightly different. Yeah. It'll be like, you got it wrong, but I slept on it, and now I have a better idea. How do we get that to human experts? I keep thinking this. Every time I think about this, I think about how the limiting factor is the access to the,  human experts.
Okay, so here's the thing we're going to do, Joseph. We're just going to build this. We should consider it. So here's the thing. Do you think the 80 percentile of humans can figure it out? That's what I keep thinking about, is it's like, I know that the top 1% could, but the,  access to them is hard, and they don't have infinite time. No, no. I'm talking about you and I have built this engine. Right. What I'm saying is like, the engine needs a community of experts. Right. Yeah. Or it needs to at least attract some experts from some communities. But my question for you was, I've thought a lot about this idea.
Is that, I don't know and I can't decide what percentile of experts it needs to make the real breakthroughs. Do you know what I mean? I keep trying to figure that out and I have a hard time reconciling, you know. I don't know but it actually doesn't matter. Because what matters is that we can build the thing, brand it, have it be live on the internet. Give it massive attention through all these different podcasts, all the different people we know, all of our brands.
With the hope that it gets the attention of somebody and they start going and looking. That's our only chance of it blowing up. And then, so here's the cool thing about this. This is what Substrate is all based on. You have the components, each individual. Yeah. And let's say Neil deGrasse Tyson looks at it, and he's like, yeah, this is, I mean, this kind of gets ruined, or whatever.
Right. Well, six months later, all the models update. Now the output is just that one. You didn't fucking change anything. Right. It's the architecture is solid. Yes. That's been, like, such a key feature of AI that's, like, fun. Yeah. And I think that's kind of mind-blowing, is that you can literally build a product with,  no doubt that it's just going to get better over time, because you know your retrieval,  is going to get better. You know your latency is going to get better. You know the models are going to get better, like, smarter.
Like that feels so encouraging. Like, it almost, like, it makes it more of a builder's world. Yep. Because you don't have to worry about whether or not, you know, you just know everything,  is going to get better and cheaper and faster over time, which is, like, so encouraging,  as a builder. Yeah. Yeah. You don't have to make it perfect, because your consistency is going to get better with new tech. I guess the other factor is how good your pumps are. And that's why I love AI so much, because I feel like what I'm good at is clearly understanding and clearly articulating.
And finally, there's a system that rewards that. So each of these gears is actually the pumps, in addition to the inputs, in addition to the models. Upgrade one or all of them, and you have massive effort. Yeah, that's a huge deal. I like that person that figured out how to make Opus do that really tough problem, and convince that guy to pay him or whatever.
There's a guy on Twitter who held a $10,000 challenge if you get Opus. I need to share it with you, it's pretty mind-blowing. Basically, there was like a prominent AI, ML expert or whatever, not, they seem like they,  are definitely a little bit academic, but still like kind of grassroots and practical. Held it like, like, hosted like a $10,000 or $5,000 challenge if you could get any LLM,  to solve this problem that he considered required actual real reasoning, because he thought.
it was still stochastic pair, it's all the way down, and it was solved within like one,  day. Oh, man. Now, like hundreds of solutions poured in, but only one did it properly, and so it's,  like a really good study in prompt engineering, but I honestly, it's pretty complex, I haven't,  even taken the time to read through it to understand it. Was it like a math problem, or what? It was like a logical reasoning problem, like it was like A swaps with B, B swaps with A. Oh, okay. And the solution had to be, the reason why it was so hard was because it required real.
understanding. Like basically, he wasn't exposing his full test set. Like it was like 30 tests that all followed a structure where like A swaps to B, then,  B stays to B, and then B stays to B, and then B swaps to A. And it was like that rule was,  going to change for the 30 different test sets. So you didn't know which swaps were going to occur. So Opus had to basically understand the system of swaps in order to successfully solve the,  problem. And that's what made it so hard. Interesting. Does that make sense? Yeah, yeah. And someone was able to get it like where it passed, 99 times out of 100, with a flaw.
in Opus. And when we get back, we'll look at it. But it totally convinced this guy like, oh, yeah, they actually are doing real reasoning. Yeah, yeah. Yeah. I'm amazed, even today, all these smart people in San Francisco, all of our peers, especially,  our peers in security. Yeah. They don't believe Emergence does it, they don't, they're just non-believers, they just, they do not get it.
And I'm like, how are you thriving in this world as opposed to the mind, right? For me it's a disparity, it's like, I knew within three conversations, like it was like,  the day I used GPT-3-5, I understood. And like, for them, it's like they've used it a lot, and see other people building stuff,  with it, and see other people building things that are actually transforming the landscape,  of our industry, and they still don't see it.
It's like the blind versus like, yeah, it's so weird. And they'll also argue that it does matter. Like I think there's also a rational ground where it's like, I still think it's a super,  intelligent stochastic area. But I think you're right, that it is simulating understanding in such a. I.
really hope 400B drops soon. The betting markets were showing June by a lot. It was like a, it was a betting market spread where it was like May, June, July, August. And it was like, it was like 10% May, 10% July, 10% August, like 60% June. So I think there are some smart people who are putting a lot of money on it.
coming out of June. So I wouldn't expect it. Yeah. I'm skeptical on how. I'm skeptical of my skepticism at this point. Right. I mean, especially if somebody doubled the layers, you got that much juice out of it. Right. You know what I want to do? I want a separate repo for Shoe Benchmarks. Yes. It's hard to come up with a good one.
Similar to the thing you just described. Right. Where it's like, what is the thing that's... I wrote one yesterday. Did you? Yeah, it didn't really work. Yeah, it disappointed me. Plus, it's very manual. But, um... It's hard to think of good ones that it can't just cheat on, or that it can't, like, find online, or that it can't... Or it gives you a pretty good answer, and you can't distinguish that between the best answers. Right. Um, the best one I have so far is Find a Hidden Message.
Yeah. Now, honestly, that to me, whenever you showed me that, was... Oh, but it just feels different. It builds on another level to that question. Yeah. Oh, I don't think I've done Opus, or no, I don't think I've done Llama on that one. Dude, context size is really killing me on Llama. I know. If that was 128 or 256, that would... Yeah. Were you able to run 7 to be lucky or no?
What? My M3 is a 38-bit RAM. Oh. I don't really want to... Like, it seems like the quant for the Llama 3 models are great. They get worse, yeah. That would require, like, a 3 or a 4, right? Yeah. So, I mean, and the 8B is good enough for... Like, if I'm asking about, like, give me a bash command that does this. Yeah, yeah. I just use Llama 3, 8B, and it's great. Yeah. And for everything else, I just use Opus right now, so...
You know the big variable that not a lot of people are talking about that I'm really curious? It's like... there's also a data set game oh yeah the data set game of like,  what do you think meta trained on i don't know but it was good,  it was really good and it's like they don't have a bunch of conversations i,  don't think i'm really curious where they got their,  data set,  i mean they have facebook and instagram that's what i'm wondering if it was,  basically like dms or if it was like chat i'm.
really curious well yeah but i think,  oh that's another market by the way what data sets,  yeah true so so if you look at like um all the data brokers who are doing the,  really nasty shit with our privacy data they're gonna pivot and become live,  feeds of the true human data,  do you think you could take something like 120b,  and make a synthetic data set by just running it,  24-7 on like your computer for the next month have it generate.
the same way people train,  the same way people train,  on GPT-Code,  the same way people train,  It would be expensive because we don't have it generate really high quality data sets,  for us. Like cyber security data sets or something. That would be sick and they start selling that. Sell that as a fine tune for like PHY3 or PHY2 or like anyone who wants to basically,  fine tune other smaller works models. Because 120B is so good, if you can run it locally, I wonder if like you could generate...
I'm going to write it down. All these ideas you got to capture on where they're just ephemeral. Well, we got it. I thought you paused it when we sat down. You did not. Perfect. No, I think it's running. I think it's running. Oh, it's still the red dot. Perfect. Hey, what is this little device? I don't know. It's called Plaud. P-L-A-U-D. Is it new? It's fairly new. That's cool. I'm wearing it. I'm waiting for the...
Rewind pendant? Or Limit Limitless now? Is it Limitless? Yeah. Rewind.ai... Is it the round one? So, uh, Dan Shipper is the founder of Rewind.ai. He rebranded Limitless.ai. It's round, but it folds in half. That's the one. Yeah, yeah. That's the one I'm waiting for. Yeah, yeah. I can't wait for that. They've got some cracked engineers. Rewind.ai was, like, pretty crazy. That's the first time that I ran up to an AI RISC that I would not take.
To let it record my entire screen. I know, it's really weird. Because... I've never installed it. Because you could talk to me something about something personal. Right. And it's on my screen. Right. And, like, three years later, would they get hacked? Right. I mean, that is... Well, it's only... They claim it's all store-decrypted local only. Right. You have to trust them. Yeah. Well, it's not just trusting their morality. It's also trusting their... Engineers. To never upload it. Yeah. yeah at any point in update could just say we're gonna take that DB just to.
train on it real quick yeah yeah yeah I worry about some stuff that gets said in,  the discord because it's subject to a government capture I feel like so many,  discords I mean people just say stupid stuff they shouldn't say yeah like that,  guy who was doing sharing government secrets or whatever in his discord group,  yeah yeah.
all right thank you for yes we can talk about substrate yeah.  yeah.
Okay, now turn it sideways, and do it again. There you go. Turn it around, Sam. There you go. Okay, now turn it around, Sam. There you go.
There you go. It's like, uh... Well, it's... It's warm. It's warm. It's a lot of work. Sorry. Oh, you guys are funny.
I can't. I thought 100 people were going to be here. I thought 100 people were going to be here.. I didn't expect it
I didn't expect it. I didn't expect it. I didn't expect it. Hey, let me take a picture for a while. Yeah. She said, you all doing anything fun? I said, yeah, eating Mexican right now. Um, I just saw in the, uh, a picture from, uh, Vsauce, Meta had a 5% bonus on your next bug, on your bug bounty by claiming it from that QR code.
Oh, wow. You know what a fun idea? It's only 5%, but it's just a fun little perk, you know. Alright, time to go substrate. Alright, so this is basically like a unified technological framework,  for solving human problems, including human meaning. Okay.
So... It's kind of like a unification of all the stuff I've been talking about. Thank you. So you've got a person. The person is broadcasting their API. Yep. Ideas. Mission. Yep. Goals. Problems. So this is the problems they believe are most important in the world. Right. Could also be parts of problems though.
Yeah, it could be their problems as well. If they're willing to share that. Like obviously that might be sensitive, but if it's like I have ALS or whatever else, you know, it might be useful for people to know. Yep. Projects, money, whatever. Okay. Kind of most important for this demo is ideas, no problems. Over here, I've already got an org. So I'm doing this at the org level. So all of these individual ones are going to be repos inside of the org. Okay. Problems.
PR 1097,  No, instead I just think about the individual. It's not for an order. Well, this is for an individual. But this problems API, the problem list will include PR 1097. 1097 is a repo. Oh, we did talk about this a little bit, yes. Okay, so problems is the repo.
There will be ideas for solutions in here. Yes. That will get vetted or added to or whatever. Well, so this is the only problem. This repo is only problems. Right. This repo is solutions. Right, it uses the same ID. Now they're cross represented. Solution 1097, right, yeah. So you would have like solution 1097 A, B, C, D. I remember that part, yeah. And then. This will just be a generic list of all these. So we've got problems, solutions, arguments.
Which could be sub-components of solutions, maybe. Yes. Or whatever you have. Claims. Which could be validated or unvalidated, right? Yeah, so arguments are kind of like bigger. Frames. So it's basically a perspective of a problem. It's like a view, which could include multiple arguments or claims. Then you've got facts, which is like, these get added to this. If it gets flagged as a fact.
Yeah, validated. Yep. So essentially what we have is the ability, if you start talking about this thing, this new startup that you're making, and whatever, you make bridges. As you're talking, my AI will be listening. Right. of this argument. It sounds like he has this frame on reality, which is why politically,  YouTube is great, because he believes the US is sexist and racist and horrible, whereas.
my frame is that the US is actually really good, it's got problems or whatever. So it's,  like, in the course of a conversation, an AI will be able to step back and look and,  be like, what frames are going on? What arguments are being made? And then validate that with real facts online, like a good start. Fallacies. It's a list of fallacies. What would you have the humans open to? It could be hugely, circularly improving. Like,
hey, when you were talking to Daniel, on your way home, hey, when you were talking to Joseph,  earlier, you fell for the straw man fallacy when you were talking about argument. Well, that's right, that's right or or when you just make that argument,  And it's been recorded. However real-time that is,  We both get sent a copy of the argument that you make,  And it's blown up in like this nice structure, but a couple of things are pointing to claims which are unvalid,  And then I make it another argument in its way worse and it's like 74% not valid.
Um, and it's like well,  Maybe your frame is faulty because you made three arguments and they were like 19% quality,  37% whatever,  So essentially, oh and then you've got like a team,  Mental health problem like you don't grow with mental health issues. What is her frame? What what is the court of the law? She believes about herself? That's a good question, what is the what is the voice she speaks to herself? How does she talk to us?
That might be hard to know, right? That's hard context to get. Yeah, you would have to like interview and have some therapy type stuff. Yeah, you'd have to tease it out based on the things she says. Yeah, interactive capture. So essentially what we're talking about is, this young girl could be like, you know, Megan hates me and blah blah blah, and she'd invite me to the party, I'm gonna kill myself, I'm just like... Actually Megan thinks you're really cool and she's just intimidated by you. Right. Or, Megan is the quickie monster, you shouldn't care what the quickie monster thinks.
Right. Find better friends. Yeah. Start sending a new frame or whatever. And the whole point is, your friendly AI is gonna start talking to you about the new frame. Making new arguments. But the point is, any human problem... Oh dude, PR number one, I'm actually, I'm not gonna call it number one, but,  the first one I'm adding is heat death of the universe. Human aging. Climate change. Right, you're gonna add the big... Yeah, at the big ones and then it's like number 37 or whatever. It's like small towns in the u.s.
Currently tend to have bad water which poisons the kids or whatever. So when I'm looking at you as this.  What my AI is really doing it for me, but when I'm looking at you it sees all your problems,  It sees the pointers to this different solutions and it's like I understand Joseph, right? Like priorities faith, I see my family I see all these different things,  It's like oh, you're gonna like this guy. And by the way, it colors you in a certain way inside of my.
right,  Well, by the way, I brought my meta Ray Bans,  You have some I don't have any good you need to play with me to order some well,  Yeah, when you play with mine, you're gonna be like I have to get this really the build quality is the same,  Like it feels like be perfect,  I.  pretty magical to have an LLM. Basically, it's like your own built-in Bluetooth headphones. Because the audio, people can't hear around you, so it plays it directionally in your.
ear where other people can't hear, but only you can. And then you can take a picture, you can ask it to describe it. So it has LLM vision built in, so you can be like, hey man, what is this time looking at? Or how much is this? How many calories is this? Or whatever. And we use the LLM to interpret that image. Wow. I'm often coaching my kids' soccer teams, so it's kind of weird for me to run around on my phone videoing them while I'm actually like,  on the field being the ref and coach. So I can just start a video, and then like get a video,  from the field view, and so it's kind of cool. Anyways, how's it been? It's been great for me.
At last, I've never had a dye on me, and the case is a charger. So if I was wearing them,  all day as prescription glasses, you would probably have to take them off for, I think,  it would probably last either almost all day or maybe half a day, like somewhere in the middle.
I bought it honestly because I thought Wama 3 was such a huge step improvement that I was,  excited to have that in an LLM, but they haven't upgraded it yet. It still uses LLM2 under the hood. So I'm excited for it to upgrade to 3 later. And they're going to do that. So, it's funny you say that because I just bought like 50 grand of Metastar because of,  seeing Zuckerberg start doing Jits, change his whole vibe. Metaverse, he's not actually out of Metaverse. He's not out fully, but he's not like obsessed.
with it in a weird way anymore. Well, he's not obsessed with talking about it because,  he realizes the AI is the way to get there. Yes. So, I think he has super clear vision. Me too. I think he's smart as fuck. He seems way more competent than Sam, just from like,  a... He seems sharper. He seems less deluded in his... I think Sam has long term vision. I think he has murky execution maybe, whereas I feel like Zuck feels like laser focused.
from like an execution perspective. I don't know. I wouldn't put it that way. I feel like,  Sam is probably massively crushing it. I think it feels like that because of the way he talks,  about things. Yeah. He's always so roundabout. Yeah. I think he probably could go into attack. I think Zuckerberg is just always right there. He's just so dialed in. Yeah. But I just love,  his transformation over like the last year or so. His couch thing, where he just talked about how bad that Vision Pro was, I think he was wrong, but it doesn't really matter.
I just, I love that he's being a real person. Authenticity, yeah. Yeah. Well, and then I saw Llama 3, and I'm like, and he's just getting ready for the next thing. He's like, oh, this is just now starting. So, I am all in on that. Open AI can obviously raise a ton of money. Facebook has the money, and the engineers already, which is a big step in the right direction. I hope that Apple does something similar.
I think they're going to do small models integrated into apps. Privacy first. I just hope they fix Siri. I hope they have AI integrated all over the place. Have you noticed it kind of does do, like, you can ask it questions now from the internet. As of like the most recent version, it's still not great, but it'll sometimes give me an answer. It'll be like, I got that from website, website, website, whereas it used to only suggest websites. No, I'll see if I'll do it. Hey Siri, who...
Hey Siri, when is the next UFC fight? That's Siri for you. That's Siri for you. I saw a really funny... I know for sure that is Siri. The next... I saw a funny thing that says, what if Apple renames Siri Iris? It's Siri backwards, and then they could do Apple Iris would be AI.
Oh, I saw that article. I didn't, I didn't read that though. That would be shit. You're on military time. Do you get excited when you look down and it's 1337 when it's leaked? Yeah, it happened yesterday during Clint's talk. I looked down, 1337. So anyways, yeah, you can keep going, I'm substrate if you have more thoughts. Yeah, yeah, so essentially the idea is I want to be able to...
I'm trying to figure out how to do this for the video. Essentially I'm going to lay all this out and I'm going to say there's two things I'm trying to do with this. Understanding of anything. That's the base level. Any argument. Well, any argument, any topic, any position, anything that matters to a human, we will be able to describe in a tangible way that an AI can walk programmatically.
Basically it can make a graph of it. It can graph it and then compare graphs and then describe things. Now, here's the second part of it. The second part of this is, and this is going to be,  one of my two,  main security AI,  things, that I'm staying fully,  in security. The explanation,  part, I'm doing for the security program. So their mission, their goals, their risk register,
their entire,  tech stack, any history,  of incidents, the policy piece will be like, we do business in France, California, you got to watch out for compliance, privacy issues. Fully articulate. Dude, I'm working on a talk for this. So, this is one thing I want to talk to you,  about with your brand. This thing that I'm doing, I have this idea, which is going to be a paid offer. It is a product that I'm building.
It's also a talk. This talk is called... How to manage your security program using AI before someone else does. And the whole talk is basically, half of the talk is, this is coming for you, here's exactly how it looks. And I'm spinning it up to be a future picture, right? And I'm like, this is coming, KPMG is going to do this, McKinsey is going to come in. And then I'm going to be like, once you have all this, then you switch to Q&A,
which is, you ask the question, which is kind of like an A. I need a report for the auditors, they're KPMG, they're focused on privacy, they want an update before they arrive on site on Monday. That's a fucking scramble, for 13 people. The CISO's best 13 people go and work on this thing to get it ready, and it takes forever, and everyone's scrambling, and they're all busy. That's 90 days. seconds, Claude writes it, or whatever. Head of engineering, they need an update on our.
shared goals and everything. Well, guess what? All of our shared goals with engineering, the shared goals with the company, it's all right here in the context. This context is,  the entire product. Then I cluster this cluster of questions and actions, which are print,  the reports, do whatever. Prioritize a new vault, new log 4 gate comes in, I slot it,  in to the proper location inside of the risk register. Based on impact, based on coverage,
based on the attack surface currently. Right? So halfway through, I'm going to be like, it's not theoretical, let me show you how it works. And I'm just going to do a live,  demo. I'm going to show it printing. So are you just rebranding same page, basically? This is very much same page. Cool. I mean, that's what I get from it, yeah. And you've already working on it, you already have a UI working, you just changed the name? Same page was this, but for sales, whereas this is this for security, so I'm going to.
name it something else, but ultimately when I figure it out, and this is why I started,  the Substrate thing, is same page and this, they're all the same, which is Substrate. It is really just articulation. Right. And that brings me to the next piece, which is action, and it's the same as this. So detection engineering, and I got this idea from Arpathy, like whenever that was, a year.
and a half ago, when he built FSD, he's like, look, these are all just little pieces, it's,  a giant pipeline. Sensor data comes in to the sensor, it goes around the thing, it hits this, all of these,  AI's are stupid. They're flawed, they're very small, they have to run locally. They all come,  through here. Now, down here at this step, or no, no, at the end of the pipeline, yeah, the Tesla hits the curb, runs over the curb. Team, what happened? You got to go through this.
whole thing, figure out where this happened. It's the same as substrate. I can describe any,  business in this term. If I have long enough time to interview, build out the components, but more importantly, for Helios, which is the other product I'm going to keep doing, Helios is going to be this for a tax service management, and also continuous OSINT and,  continuous recon. So I can just put in any person's username, it goes out and does with.
all agents. This can be prompts, this can be agents, this can be data stores, doesn't matter. security program doing detection engineering, it's like, you've got sensor data, it comes,  in, you do some, LLMs aren't going to do the base processing because it's just too much,  data, it has to go too fast, but when that thing fires an alert, that goes into the pipeline, you run some kind of models against it, whatever, it produces some kind of output, so, tier.
one SOC, eventually tier two SOC, incident responders, all those different things, they're,  just pipelines. At the end of the day, their actions are just things that can be automated. Yes. And over here, just like the substrate thing, or the understanding thing, first you understand,  your business, you understand your pipeline perfectly articulated, then you say, some,  of these steps are an actual action, a report shoots out.
Findings you talk about. Log on a host. Yeah, or reset a password. Yeah, kill the account, whatever. So.  this product is essentially, or the other product, the security program product, is going to be, they enroll everything,  and when they need to go print the report, they print the report and they're good to go. They can basically manage it. Oh, dude, the thing I'm doing for the demo for that talk,  is,  the metrics board is going to be on the screen, showing their main KPIs, like percent remediation or whatever.
Dude, I'm going to shoot in new data,  from a source, like a new metrics update. Dashboard live updates. And it's like, and then the punchline for this entire thing is.  who here, because this is a CISO talk, who here can currently do this? And they'll be like, not really, a couple will be able to do it, very few, but I'm going to like, look, a lot of you don't believe in AI.
This is coming true. What's about to happen is McKinsey's going to walk in the door, not go to you, they're going to go to the CIO, the CEO, and say, this is what I can offer, real-time updates, real-time reporting, a full articulation of what we're doing, the benefits we're getting, how we're helping other groups, shared goals with the rest of the world. This is the new standard for a security program. It's all going to be powered by AI. The question is whether or not you're going to give it to them, or if KPMG's going to give it to them.
And they're going to shoot their pants. They're going to want to be the one that brings this to their org. Yeah, yeah, and I'm going to be like, look, if you already have this ability, then you're not as vulnerable to anything.
or state, by pushing in like a breach, push in an incident or a breach, like a fake one,  into your fake company, into your action report, and watch it change the messaging for their,  CEOs or for their, you know what I mean, if it still looks like same page, you could watch,  all of the current top priorities get shifted, that would be really cool to watch that happen. Rerotate the risk register. Right, yeah, exactly. As a result. You should make that a part of the demo, that'd be cool.
Yeah, that's a good idea. The one I did last year at Black Hat was this connection was allowed and then the CISO sent,  in a report and now the connection tried again and it gave the reason that the CISO now made,  that against the policy. But using this structure here, this is the future of hacking, this is hacking.
So Helios does this for ASM but it's going to be the same for Bug Battle, it's going,  to be the same for eventually for Red Team because, and this is why I love AI so much, it's like team, what do you do? We do different things so if you can't write it down in this format, show me exactly who's,  doing what, that is the power of this. And that's why I'm calling it sub-sub. for all of humanity, because if humanity could understand itself in that way, now we can.
meet with these other people, and be like, look, we both, okay, guess what we have, pointing,  like this with a green around it? Let's raise healthy kids. We all want our kids to be happy. Look at our shared goals. And the AI could find a really cool way to like, highlight that, make it big and be like, Oh, we've got these minor details down here of like, there's some land issues, some religion,  issues or whatever. But ultimately, we're trying to do this. So whether it's ASM, or like solving world problems, right?
On the hacking thing, I think that this, I've had this thought for a long time. This is what the way that you should articulate this to others, is that right now, this is,  the world. Like the world right now is humans. Basically, you have some humans in your org that do these jobs, and you have some humans,  in your org that do these jobs, and you have some humans in your org that do these jobs, and that makes it confusing to end up with this graph.
But what actually, and so I think that what a lot of the AI companies right now are trying,  to do, this is like the AI bad attempt, is a lot of companies are coming in and saying,  like, AI is going to do this, or AI is going to do this. And they're going to fail. This is going to be snake oil. I mean, this is what they're trying to get agents to do right now, and it's why it's,  not productionized ready. But the reason why I like this is because the real solution to this is designing an.
agent that can do this. 100%. Like, instead of building a hack bot that can do XSS and SSRF. We need to build an agent that is the world's best SSRF client. It's all about the components. You just need to give it a single request and say, find SSRF in this value. And guess what? When it's amazing at doing that, you pivot and you write the world's best XSS finding,  AI agent. And then when that's good, you go to the next one.
And guess what? Eventually, you have an agent that now can call all these endpoints with what it thinks,  is the most likely vuln to be there for a specific request. And now it can find all of them. But if you just try to build a hack bot that just says, what vulnerabilities might exist,  in this? And do your best at trying to find that vulnerability, it might do okay. It's going to find 2% of bugs. But with this strategy, I think you can near human level of... Actually, you probably would surpass. If this system is being compared to a single human, it would destroy it.
If this system is being compared to a team of humans, it might start to compare. But if you keep building it like this...
are you doing? What do you improve? Right. Because here's our current efficacy numbers,  for SSRF. Right. Does your model do better? Show me your efficacy numbers. And they can't,  be like jazz hands, they got to show you numbers. And it's like, okay, we'll do a hot swap. And dude, because the protocol coming into this thing, and the protocol going out is,  the same, you can do a hot swap. Right. Yeah, exactly. In the SSRF vendor, you just drop,  it into your agent and now it's a tool.
And that's what I love about this is like, to your point, this,  could be a dumb function or whatever, because the AI is,  actually sitting back here. Exactly. And it's the one that,  kind of understands. It's just like in LinkedIn, you have a,  description for the tool. Yeah. So that description is what,  tells it this is the SSR. Right? Yeah, this tool could be nuclei,  doesn't have to be AI, right? Especially like right now, that,  would be the best way to do it. Yeah, you would want to have a,  param finder called Arjun that finds more params or whatever,
you know, like, yep, all of these are not going to be best,  in class as AI right now. Yep. On the KPMG side of things. Hopefully, they will be able or Mackenzie or Accenture. Hopefully, they will be able to say like, yeah, we do AI here. And right now we're using humans for these because our humans are,  really good. Right, but we're working but we're working on,  getting AI here and here. Right now our our humans that use AI,  are actually way better than AI by themselves. So are we.
I remember you did do an overview a little bit of substrate. So what does substrate mean outside of the context of this? I just want to understand the naming. Like what is substrate? Yeah, substrate is the underlying shared infrastructure underneath the thing that you're talking about. No, yeah, I'm just saying like in chemistry, what is substrate? It's the liquid that everything else goes into, right? Oh, I don't actually know the chemistry. Flip it up. I don't know the chemistry. I know the physics.
It just says underlying, an underlying substance or layer. Okay. Yeah. I'm going to be using Google like a noob instead of, uh... Yeah. Donut says hi, by the way. Oh, sweet. How's he doing? Good, I think. He's, uh, launching... You know, he's at Robin Hood. Yeah. So, he's been helping launch their, uh, gold card. Have I told you that I got the gold card yet? Robin Hood has a gold card that's 3% cash back on everything.
Yeah, yeah. Yeah. You have to have Robin Hood gold, though, but it's worth it if you... We were actually on the same team. You and, uh, Donut were? Yeah. So, I was the manager of that team. Oh, cool. And I hired Donut at Robin Hood. I didn't know you worked at Robin Hood. Yeah, yeah. Oh, cool. Yeah, yeah. He's still there, yeah. Yeah, he's still there. And, um... Do you want me to get some tea? Yeah, Ian's doing the flight thing. Dude, it's crushing.
I think he makes around your salary. I think his ARR is $750k right now. Oh my god, dude. That is... He's in that lawsuit with Air Canada, do you know about that? No. Yeah, they sued him. Basically, he scrapes with some of their APIs, right, because like, that's how you do their,  service. But, and there's lots of other companies scraping their APIs, but for some reason he got on,  their bad side, and so they're suing him, which I think they're gonna either settle,  or he's just gonna win, because he never signed up for an account, so he never agreed,  to not. Oh, okay. See, it's in the terms of services that you're not allowed to abuse it, which he doesn't.
even abuse it. Oh, and also, he found a blog post where they bragged about how resilient their architecture,  is and that it can handle like 60,000 requests a second or a minute or something. Oh, wow. And he does like one thousandth of that. Oh, wow. And so he's able to use that in court as like, you know, you said that your systems can handle,  all of this load, and I'm doing like one ten thousandth of that. Right. So you can't claim that I'm disrupting service. Like you bragged about it, you know. But anyways, yeah. Are they turning off the public thing to stop people like him?
They can't. The entire, this is the reason why C-Side Aero is so good, is because the entire airline,  industry is very, it has to be open. Because all the other airline providers and all of the airports use those APIs to coordinate,  with each other. Okay. So like they can't shut it down because everyone uses it. I figured that would be the case, but it would be like, like Swift, like on some private,  network or something. Oh, interesting. Wow.
That's why you're able to, if you just like have someone's confirmation code, like look,  up their entire flight details and everything. Can we just pay at the front? Yeah, yeah. Okay. I thought we were waiting for you to come back. I got this one, dude. No, no, no. What are you talking about? You already gave me all kinds of free stuff and you're hanging out with me.
Oh yeah, that's what I was going to tell you. Yeah, like my newsletter or whatever, my email list, I'm trying to call it that,  instead of newsletter because I don't like the obligation that it's putting in this facility, but it's like 1,800 people and.  but it's something like a thousand or something or just like,  a beehive of pearls here.
Just riding on your coattails. Yeah, I'll give you this in advance, honestly. I don't feel like it's a hard number to buy,  if you roll that up on me. I think it is. I'm like $4 something. Yeah, it's $3.50 before,  a high price. Dude. It's like, you know, I know you would definitely want me to and recommend,  me doing my own thing. And I still have some places to go. They gave me golden handcuffs.
I mean, I wasn't like $200,000 before that. That's hard to walk away from, dude. I really,  think we're going to exit huge. Like, we still have all of the Fortune 100. And they gave,  me a new ISO vest on top of that. So I still have the opportunity to leave in December,  because that's when I hit my cliff of like my one-fourth vest. And I think kind of the,  VC networking I'm doing right now will lead to more adviserships. Yeah. And so I think,  doing basically...
Maybe it's now, I don't know. I think that, I think there are probably,  some really creative subscription-based services,  that, I guess I'm trying to say, I think there's a hole in the AI security space. Yeah. Not AI, not security, not using AI to enhance security. Like, I think, like, you, Jason, Clint, and pretty much, like, lots of other people,  who are already deeply networked,  in this cybersecurity space are going to.
you know, continue to learn and apply AI and show how to do that, basically. But I think for the AI security space, if I was completely, like, if I just lost my job today, one thing I would probably do is start a podcast, because I think there's no AI security podcast,  right now, like, that talks deeply about, like, prompt injection, like, jailbreaks, that sort of thing. And I would probably want to co-host it with somebody who's more,  technical in the sense that they could talk about, like, gradient descent, like, kind of, like, adversarial. Yeah, yeah. Like, probably Kyger Shockey or Johan Wunderberg.
And I asked them, and they both would be open to it. So I may do that eventually. I've considered,  starting it now. I'm just doing it really small. But man, my time at home with the current three,  young kids, they're just, like, time gobblers. So it's tough. But I think as soon as I leave,  at Balmany, I definitely would be willing to do that. But anyways, outside of that, I think, obviously, your subscription model for supervised learning has been incredible. And so that's, like, the primary contender. But also, I'm open to just, like, other... What do you think is the prime directive here?
You want to super super know the overall vibe that you want to have and what you're trying,  to actually build 5-10 years out from that, like what you want to be known as. And I would caution against anything super technical. Smaller audience? I wouldn't think about audience at all. I wouldn't think about audience or numbers at all. I would think no matter what, you have to do a podcast. No matter what, you have to do video.
So it's basically, this is very... Those are just rules of the game. I would say this is the rules of like starting a year ago. If you want to have impact on the world, you must have a reach mechanism. Yeah. And this is essentially your reach mechanism is YouTube, podcast, whatever. Yep. So the question is, what are you broadcasting? That's the most important question is ideas. Yep. As far as community, I think you should just start growing it now.
I would recommend doing basically the same pricing model as me, like 99 a year. It's fairly cheap. And I would say for now, it would be the ability to talk to you in discord combined with the,  ability to maybe get some custom gear or like custom content occasionally. See, I do like the idea of custom content, but because I think it snowballs, like this,  is one thing that critical thinking is doing.
Basically Justin and Joel are recording like little master classes. on specific vulnerability types, and their catalog of those grows. So the incentive to buy into critical thinking or to become a critical thinker grows over,  time because eventually in like a year from now, there's going to be like 50 recordings,  in there. And by paying once, you now have access to all of that content, right? And so I think that that is interesting.
My counter argument to the community thing is I just hate that every independent thinker,  now has to have their own community. I don't want like a Joseph Thacker community, but I think maybe managing and contributing,  to an AI security community is something that I would find interesting. Just because I feel like... It's too much cult of personality type vibe? Well, no, it's not that. It's just I feel like...
I already feel this overwhelming sense of, like, I only live in a couple of discords. Like, I check Unsupervised Learning's general channel now. I've kind of stopped checking the smaller channels. And even for the critical thinking, like, I only really check the critical thinkers, like that one I was telling you about where the custom content gets posted, just because I only have so much time, right? And I know that lots of other people are that way. But, like, a long time ago, I used to spend a ton of time in the Hacker101 discord. Like, it was great. But I literally haven't opened it in, like, forever. And so I don't think...
And I guess we can talk about this from a meta level, too. This is kind of why you have Threshold, right? It's because you also fill this pool of... You can't consume all the content. Yes. Dude. V3 feature or V6 feature of Threshold. Summary of Communities. Oh, interesting. Have it read Discord Communities and give a summary. That's big. Oh, shit. That's big. That is really big. That's so much value that no one's providing right now. And it's super, fairly easy, I think, with scraping.
There are bots that do that already, yeah. Do you have to install the bot in that community, or? I don't know. Either way, though, that's a big idea. So anyways, yeah, I think this is a problem,  we have to solve as humans, and this is something,  that AI's gonna help us a ton with. It's like summarizing all of the chatter,  going around for all of the... Like, I mean, actually, Reddit kinda solves this,  with the subscription thing. Like, you could subscribe to a bunch of subreddits, now your homepage, you refresh, you get content from all those things.
Maybe Discord will have that eventually, where it's like, for your, like, you can only read your friend's messages,  across all of the shared Discord you're in, or something. That'd be kind of interesting. So this is a good example of where I'm trying,  to not build the intermediate, because I think we're getting very close,  to we're never going there ever again. Like, yeah, yeah, yeah, like, AI's reading. Our AI, our AI, we define the inputs into it very similar to threshold, so essentially.
threshold is going to be the new thing, but it's an agent running thresholds, and then,  the agent is the only person that talks to me. V10 threshold idea here. It handles the output. What do you mean? You want to reply to some discord message summary that it gave you, it figures out where,  to send that message for you. You know what I mean? Like if you want to contribute to the conversation that threshold is serving to you, you as the.
maker of threshold have an index of where that data came from, and then if they want,  to reply, they can reply in threshold. It goes and sends that data back to where, that's a V10 feature. I know that's huge, and that's like big long-term vision thinking, but that's cool. Basically threshold eventually just becomes the DA. Well, I mean, that's what I would like to build. Well, actually, no, it's like that graph we just drew. Threshold, in my life of actions, threshold is the content node. You can turn threshold into the content node, the input-output for the content node.
For my digital assistant, it talks to threshold for my content. And it also, potentially, with that V10 feature, when I want to contribute back to the content,  game, threshold handles sending that content back to where it should go. Yeah. Yeah, that's super safe. I think that's the right architecture. Dedicated to that one purpose. Yeah, like, oh, actually, oh, man, I think we can whiteboard this out. Threshold, being the content node in our own life of actions, would fall under the state.
Remember, I was talking about how I want to delineate all of the nodes,  under SQQA. The threshold node lives under the S. in the graph I think you need to put this on your blog as a as a diagram you,  know I mean where you show nodes underneath SPQA as columns like you,  just drew with me mm-hmm in the McCarthy style yep and then you explain how,  threshold is that node of that thing.
mm-hmm.  yeah and also industries could fall under there in addition to specific,  instances.  okay sorry I derailed us from the reso brand.  thing let's do the the resident brand on the whiteboard like right now.
we have so many things to break down I did I did.  If we draw it really neatly we can put a picture in GPT-Vision and see what it comes up with. Do you know any of your neighbors?
Yeah, I know him. That's Abdul. Any techies living around here? All techies. Everyone that lives here is a techie. It's 90% Indian and like 10% Chinese. All tech. All having little kids. Nice. It is super cool. Yeah.
You got that yet? No, that's sweet. Nice. Apple watch, unlock.
Oh. Oh. I'm able to count death, space, and sleep. Lockpick Angel want me to write him in the shoe. And S.P.D. So, uh, yeah. After a rat basic problem. What are they? Thot. Um, toot. Let's fill in this. So I've gone back. Good. Pretty easy. Reese is gun as a sir. Right. But what happens if we use a wire? No meat. Lass. Here comes Neal. Unicase. My whole fic. Wack. Works. He's just like.
Be like. Um. Well, right. Button's a job. But for. Parable. To use. Not gonna. You remember the Pacific? Like. It'll be like. In a while. Death. I'll be. On. Every. Time. Automate. And I'm. Doing. Versa. From. Okay. Impact. Very. Is. Me. At my. End of time. I'm. See. The thing. Do. Probably. So. My mind. Went. Here. Out. And then. My engine. Could. Well. Run. Somewhere. Somewhere. Whatever. It. Be very. Low. Yeah. That's. Re. Uh. Deep. Re. System. I know.
Vegas. I get. All day. Uh. What's for food with that, what do you got? Anything? She's good. Alright. I also want a... I don't like... Oh, you care about like... So, what are you... I don't... Right. Just gonna... We'll do it for you. We'll get you. It goes... Is that what it's on? That bad? I even... It's bad. Yeah. Go water. How it goes, Al? Do you set read for a way... Like current vision? Just coach you for it.
Like... Yeah. Are you saying that... I have a pro question. When... Roll the... I don't... Freak out. It's worth... Many questions. He doesn't listen. He has to be... Somebody... I don't... Right now. In the row, he like... Like... In the back, right? Yeah. And we're... Yeah. There's like four... But... You just kept playing in time. I think... Yeah. He probably has... Okay. The fact that we... See your talk...
In a whole video. Family. Yeah. Two by two. Three parts. We get... You know, I hired this back to brand. This too. And yeah, I got a new one. Actually a lot. In the pocket. You can think of what you can observe. Here's the clue. Humans. Every time they talk. Or any idea. How to act. There's how to beat the wall. Yeah. And then baseball. Whatever. That's real. Naturalistic. Product. Smart. Older. Yeah. Traditional.
That guy saw the name. Actual. If you get his name. It was all I'm getting. There's a like. A swap. Had to be. Okay. And there'd be no swap. Mmm. At times. Reasoning. Do you even work here? Do you even work? Read content. And. And they. Matter. Super. Anything. I'm gonna take more of it. Good person. Dude. Nice to meet you. Shoot. Subscribe. They can't. Pretty good. Feels.. Yeah
Yeah. Yeah. Yeah. Yeah. We're going to talk about subscription. Any other ideas? Let me see. Yeah. A problem. Yeah, whatever. Repo. Is there a problem? Whatever. It's a nice. Are you? Yeah. Mentored to them. It's a startup. You choose as a manager. We're going.
You were talking. You were talking. They were. What the. So like. Right. One. Mike. Joseph. Side of. What. I hear around. Driving. Business. Bread. Phone. So we're taking. Like. Like a. Animized. Let us. Do that. Jet. I think. He executed. Always. His. But. I saw. For the. Model. Have you. Not. Not. Not. Not. Not.
Not. Not. Not. Not. Not. I'm going to be on the. I'm going to be on the show,
show, I'm going to be.  I thought 3% did harm.show, I'm going to be on the 
Yeah, he left with 2 dollars. He never allows for that. It's allowed, I think, sir. Those eggs, everyone, look up there. And they've been dissenterships. Obviously, police will then be left. I think this can decide a case to do a subjection. I'm going to do that. If you all are conning about a matter, so it's the A or 2. It's important. Custom, basically.
Eventually, I pay. I just, man, I would. It's just the end of the. Like, I only have 710. So, I don't like your content. You're a rig. To provide our boss. I don't know. And this is around. Like, you can't discord. Sir, we're never going to disengage. No. They're too patient. Make a lie. I know that comes with my case. Like, and it also. K, dude. Would him. Lenny. No. No. Shoulder. And. Hello. Draw it, if you're a nigger. I'm the end of all times. You got the apple?
Muppet. Capture. Doing this as a rishi. Hap. Heed. Sir. Top left like your slip. Parade. Think that. Eve. Strangely it's a. Thank goodness. Like you're a. Smanny. You also get out. Here. I. Do this. I. Old man. It's her. I could just plan to take over the world. And you know. Clint's gonna join us. The second day. Um.
Like I'm traveling all business class now. Nice. So it's like. Get us business tickets. Schedule it. Yeah. Find us some chateau on some mountains or something. Like. Bring in a chef. Right. You know what I mean? And. We're just going from place to place. And. I don't even ask her about the money. Right. But she knows to find it as cheap as possible. great experience. Okay, so let's try it this way. Let's think of the ideal life. What is.
so much of that Chateau thing where we're arranging this thing through our EAs? Yep. What is what is that? What is a typical like interaction look like that you just love five,  years from now? I want to work backwards now because I feel like it's really easy to just,  explain to you what I would change in my current life for an ideal life. Because I feel like, yeah, so basically I feel like I've been prioritizing health really well. Like I kind,  of like lift some, run some, BJJ some. Mm-hmm. And then I feel like faith is prioritized well,
family is prioritized well. Yeah. So I think basically the things I would change is instead,  of working 40 hours, I would work more like 25 hours. I'm definitely gonna work, but I would love to be able to do BJJ one or two times more per week. And just spend a few more hours per week with the kids. And neither one of those are bad, like they're incredible right now, like I'm extremely blessed. But it's like in an ideal world, I would say it would be reduce work hours by a little,  bit.
And then, yeah like you said, I think from the finances, having to just not care about,  like, oh we're not going to have to source our laundry, right? Or like, basically like save time in unique ways that we can't now due to funds or whatever. Would be another one. And I don't even know if we would do those, that would be much more of like a, if it's,  needed.
Oh sorry, sorry, now you, now yeah, as far as actual work. So I think my engineering work is basically me being paid like a huge amount of money,  for learning the skills I want to learn anyways. What would I actually be spending my time doing if I was not a full-time employee? Would be much more on, I feel like, the content creation, building fun side things, like I,  would say I would do a little bit more content, a little bit more hacking, and a lot more,  solopreneur or a lot more like bootstrap startup, like something bootstrap startup-wise, like.
basically one of the little side hustles that you're doing, right, like build an equivalent,  of something that I'm passionate about, of a Helios or, you know, the innovation engine, right, like the things that we're talking about. As far as conversations that excite me, I would,  say just basically stuff like this, right, I mean talk with people who are also have long-term,  vision. I don't have that many people in my life that, yeah, I would say there are not many people,  I think who really can see the future in the way that you and I do whenever we have these.
type of conversations. Yeah. I would say more of those. No, it's insane. Like, I think we both know people who are smarter than us in some ways. Yeah, of course. I don't know. Like, you're literally maybe one of the only people. I think Karpathy is obviously thinking about similar things and ahead of us in a lot of,  ways. Oh, man, it made me mad when he tweeted about the LLM in space, like, yesterday or the day,  before. Did you see that? I heard about it. I didn't see it. Because I told you the same thing, like, weeks ago.
His audience is way bigger. But he tweeted, clearly LLM is one day right in space. We pass it through the NASA thing and we send it out into space and it talks to aliens. And I'm like, how does that make sense? See? Months ago. Okay, so my audience was less. Yes. Yes. So, alright, so let's see how we're going to get here. So... You left the dash on both, so I'll talk to you later. that was like a part of your strategy was like the list can always grow you had a dash here and here,  and because you did that i thought it was like oh daniel always leaves a dash so there's always.
room for the list to grow yeah kind of um all right so.  all right let me give you this this vision thing what i'm thinking of.  and this is going to be exactly what you're already thinking but hopefully in a different way,  yeah i mean i think that's what i need basically so that so the human 3.0 thing vibe is.
i i think all of us but you especially should be thinking less about these actual categories,  yeah and more about this concept of what makes me resonate yeah um okay just really resonate,  there you go oh resonate yeah maybe.  Yeah, whatever makes you resonate is the thing that just like this what you're so you can't.
shut up about. Yeah. So one thing that you have to do that's very much like what did you tweet that thing about,  space? I don't remember. So you can't ever like one of those. I know. It cannot live in your index cards, it cannot live in your notebook instantly. You need receipts. Yeah. You need well not only that but it also I might see it and be like dude you got to do.
something with that. Right. Or somebody across the world would be like oh have you thought about doing a talk on,  that? And you're like I guess there's a thing here. Right. And worst feeling ever is yesterday when you see it from someone else. I know. So. So. So I'm. getting away from like,  first of all I think newsletters are a little bit fucked,  because AI is going to do it so well,  I think newsletters are... it's just getting saturated,  even YouTube I'm not expecting that to last that long,  it doesn't fucking matter what matters is.
slash ideas,  which will,  this is one thing I haven't actually technically solved or figured out how to,  even start working on it but,  this personal API we have to figure out,  we have to get all of our ideas into it all the time,  yes so,  I will soon have this running for myself in some kind of crude broken way,  where.  it just lives in the cloud and there will be an end point where you can hit,  and that will be a list of every idea I had.
I had this I think I even told you about it it was whispered in ocean,  basically I say,  so this just starts recording,  you say the idea,  you hit the button,  it goes to the LLM.  It lets Opus extrapolate on your idea, and then it saves it into my Notes and Notes, but it's broken right now. But I think that's basically what this is, right? It's like, you want to be able to idea capture any time, all the time. You want to always be listening, and then that goes to Ideas, and it fills this out, right? And then shares it with the world via Tweets, via whatever, and you can obviously go back and harvest those ideas for products or for blog posts or for whatever.
Well, and the biggest reason for this particular end point is for me to match with people. That's true. Right? You can also go review it yourself and be like, oh shit, I didn't do anything with that. But this would be unique, you came up with it yourself. Right. And really importantly, like, I'm going to look at some of my peers who are my friends and be like, you don't have anything in this list. You're this much accomplished, you're a total badass. What the fuck are you doing?
Right. And they're like, oh, that's not mean. It's like bullshit. That's everyone. Right. And they're like, oh, that's not mean. So, populating this, you've already had, dude, you've had more unique ideas than most of us in, in the industry, right? So you start populating this, that starts filling out. But most importantly, the moment it pops in there, you're either you're,  either sending to a thing like this, Notion, whatever, but.
you're getting it ready for, it'll be in the newsletter. Right. Even better, or Mosey style, this is what I'm doing. I'm about to go fucking nuts with YouTube. 37,000. It's like 37,000 clips, because that one little piece. Right. That's going to be a 37 second video. Right. Those are all pushed out into the universe, and,  this is a thing I was going to tweet this morning when I woke up. But put the signal into the world, put the signal into the world.
because I've seen this for all these years I've been doing this, just having,  the signal out there I get the most amazing emails. Right. From a random like,  girl random place and she's like I've been thinking about this for three years,  and you know you put it in a different way here's the blog post I wrote about,  it and it's fucking amazing. Right. So you can't let anything live with you and,  basically you you want to just vibrate like this resonate like this more and.
more and then here's the critical critical piece and you got to set this,  up soon. I'm transitioning to this I have a team right now but I need to,  formalize it even more. This is all your social media everything you only do the,  idea part. so your idea nugget starts small with like the one little idea you had while.
we were driving you're like oh shit right you capture that nugget then,  you're like okay well do I record into the thing and send it to the team,  that's just an input I drop it in slack start working and they go and start,  grinding on it and dude a lot of these videos that fabric one 70 minutes lots,  of clips in there sure do they can put out content for a year yeah they're,  really on the same thing right just like Chris is doing just like Hormozy right.
so I would say get this populated in the more you do this and this is blasting,  the more you do this and this is blasting now you're just putting it out,  all the time right now you're on the top of everyone's mind because you're so,  loud right you're just everywhere you're yeah you got so much volume and I'm,  literally going now to,  I just posted to Instagram for the first time in like seven years. So, whatever- How did you create a business account for Instagram? Basically right now it's just like- Well, I just logged in to post and it was like,
do you want to make this business account? I'm like, yes. Oh, cool. So it took like 10 seconds to convert. So, whatever this current list of like popular things is, you tell them blast to there. Right. Um, now as a result of that, you're now being asked to speak. You're now being asked to speak about what? The same fucking shit. And it's not other people's shit. That's your shit. Right.
Oh, um- Oh, dude. The amount of context I'm about to have in Fabric. So, dude, the what's it called? Because of your original idea- Context.ind. Uh, well, yeah, with the switch C. Yeah. So, when you do the switch C, I'm writing a pattern for panels. So, it happens all the time. They're like, hey, so what's the deal? You want to go do a panel with us?
And I want to just echo into it, the topics that they want to talk about in the panel. It's going to read my context file. Right. And then auto-formulate my topic. Reverse the questions, yeah. Well, you know how when you go up there you're like, okay, I need to have four things I'm going to talk about. I'm going to have it auto-build it. Right, that's it. And then, of course, I have to keep funneling into the context file, but whatever. What's kind of funny is we're like, we're treating ourselves like an LLM.
Yeah, it is, right? No, I mean, like basically this is all context,  that just lets us be on a loop where we have more ideas. Where there's a generator. So, yeah, so we generate more output, which we then, you know, obviously we have context coming in from the world. But then, yeah, that basically. So, what do we got? We got, okay, now you're consulting.
Right, basically, who are they going to go to when they need help with this? They come to you because you're all over their feed and you're all over their timeline. You're all over everything. Yep. Oh, and then the ideas also go into products. We're going to build shit. So, what I love about this is I don't have to focus on anything except for this. Right. This is my whole life. So, as I'm reading the books, the books are coming in here.
It's like I did in the augmented thing, right? You have all the inputs coming in. So, the books are coming in here. The podcasts are coming in there. The person, that's a person. And then...
I don't know. I haven't heard from him in forever. I don't even want to see the results of that. It's weird because Moxie got out of Signal. He's no longer involved with Signal. So maybe he's going to replace Signal? Yeah, Moxie and Jack working on something.
Anyways, I love this. So, what are we missing here? Hacking? Well, that doesn't matter. That's just here. It's an idea. Content? That's already there. Use money to get time back? Basically, all of these come from,  this success, which just comes from,  capturing this better and articulating,  it better. By the way, I just hit 49,000,  so I'm so close to 50k,  Twitter followers. I still get so low engagement.
I think it's because my,  audience is so fragmented. It was very bug bounty, and now it's very AI. So the algorithm matches,  your followers' most likely interest,  with what you're tweeting about. So when I tweet and it has the word,  hacking in it, it performs way better,  than it tweets when I don't. Which again, like you said, it's just this. Just don't care about it. Just keep working on this. This success will come. run that because to this day if I post anything related to hacking, attack.
surface management, recon, it fucking goes crazy. And I'm like guys I've,  been trying to transition for all these years and they're like we want to hear,  about hacking. But you know what's crazy is you don't even have to put,  money on this chart because doing this makes the money. Like this is that's,  gonna make money, that's gonna make money, that's gonna make money. Dude there's,  nothing funner than being flown business to go and oh dude my last few talks.
Paid. Well so the last talk I did in in New York was like the first time I've,  done a talk after this transition where I've fully woken up. Yeah. Because I've,  always, first of all I was an introvert and like socially awkward, I still am,  sometimes, but like that's I've always been that person. Well then I've... force myself to get decent at giving talks, but I was still up there, you know, it's talk, blah, blah, blah, it's technical. I'm performing a talk.
That's awesome, yeah. This last time, I literally went up there with an idea that I think I have that they,  don't have, and my goal is to wake them up to this idea. Yeah. And it was the transition, it was the human 3.0. Sure. It was- And you're so passionate about it, it doesn't matter if you'd prep or not, you'd be up there,  speaking like- Yeah. With emphasis because it's like you're excited about it, it's bringing you a lot, you're,  resonating with it. Yes. Right. And so now, dude, people come up afterwards and they're like, I didn't see it that way.
before, and they're like, this really can be positive. And I'm trying to show them how bad it can be, and then be like, like halfway through,  I'm like, look, I'm worried about this. I believe there's this better thing which we can build, and that's what I'm- trying to build right now. Yeah. And that's how if you switch your frame towards that, you'll be happier, right? And you can make some cool shit, and it'll be better for everyone. And it is invigorating to have a talk where I'm not trying to explain a technical concept,
right? I'm trying to like change my vision. Yeah, you're trying to like, or spread a vision,  really. Yeah. So what, yeah, yeah. So what, what parts of this? Oh, so I think there's a piece,  missing here for you. Okay. Yeah. Tell me. I'm open to any kind of suggestions or criticism or,  anything. There's a piece missing here for you, which is maybe will be weird for you. You need,  to get this over there. I know you recommended that in the past. Like in your full self. You.
recommended about Kodass. Yeah. I've had a ton of people reach out about, I mean, just by having Christian in my Twitter bio of like, Hey, thank you so much for being like, So, for example, so I think it's likely to be somewhere around here, but they can be,  free products or services where it's education or something, similar to what I'm about to,  do with, so my first class was augmented, my second one's going to be called aligned.
So it's basically how to build, using Substrate basically, how to build a career where you,  can have meaning and purpose. Let me explain the problem about why I think that I haven't, and then maybe you have a,  good solution to it. Okay. So basically, I feel like it just needs to be a different stream, because I think that,  there are products, consulting, speaking, and even outsourcing in the Christian space.
that need technical experts and even thought leaders and people who have strong opinions,  about AI. in the Christianity space like I think that we need that and I think also,  there's like a lot of value to add to parenting and being a good dad and like,  you know promoting family and even just family values and all that as well with,  my perspective but I think that those feel very unimportant or irrelevant to a.
lot of the to the rest of my brain if you will in a way where like I guess I'm,  saying I don't want it to niche down the value I can provide with the other,  things I think it's the nicest way to say it the best way to say it because,  I'm not worried about its impact on people's view of me because I think,  they're net like they're like net good by far but I think that it almost,  niches me down by talking about it maybe that's not the case no I think.
people do have expectations,  they're like, okay. So stay in your lane basically, right? Yeah. I'm here for prompt injection. Right. Not, not for Jesus. Right. Yeah. Yeah. A hundred percent. I think maybe it's just like a specific channel. Like maybe it's a different, I think it's kind of like, Hey, look, I'm super passionate about prompt injection, uh, or more importantly, AI and the future of AI and security and everything. Now I'm also a Christian and I have this other thing. If you're interested in that, there it is. Cool.
But like you're not forcing it down that lane. Perfect. So basically, yeah, you, you would, I think that's smart too. That's cool though. But yeah, so basically my ideas that are in the theme of family and religion still go in,  my idea bucket, but they might not go to the same syndication channels. It would be a separate, you know, consulting, a separate product, a separate engagement, whatever, but it's just more arrows. It's more output, but they still are going to be my ideas. Cause I'm obviously going to still have those ideas. It's like, it would be silly to not capture them and.
add value to the world through them, right? Absolutely. Okay, cool. Yeah, and I think ultimately like you're building, oh man, I came up with this thing, I did a,  short video on it, people want meaning in their life, the way to get that is to have,  a purpose, the way to have a purpose is to be... Oh, I definitely saw this, yeah. Useful, way to be useful is to work on the most important problems.
It's exciting that it can be turned up. Oh, you did send that, you did send that. Yeah, and then what you're good at. Yeah, that was, I know you often talk about dopamine hitting, whenever you mentioned,  that it can be inverted, that was like super mind blowing to me. Yeah, and so when I think about this stack here, for you, I feel like this is such a,  core part of you. I would just want to see you producing usable outputs by people to be useful in that way.
Yeah, I think you're right. And I think it's so easy. I think the solution I had not thought about was just having a different channel for it. Which on my blog is easy because there's a faith tag. I can post about it. They don't have to read it if they don't want to. I'm not going to send that out to the email list whenever I post about faith, but it's,  there for people to see if they want to and if they want to go to the tag they can. But then when it comes to things like those ideas or a product, I'm sure that I also have,  many similar creative ideas. Like, for example, in the family one, I do post about the hacking, or sorry, parenting.
hacks. There you go. And those posted really well. I got a ton of amazing feedback from hackers that are like, I'm a dad and this was so helpful. Well, there you go. So it's already emerged. Right, right. Yeah. But as far as like, let's say I had a unique perspective on a theological debate about,  AI or something, or like, yeah, like a Christian view of AI, for example, like what that would,  be.
What else do we have, I think this kind of covers you, except for, uh, Mission, Brand, Tagline, Single Sentence Summary, what would you think of that for yourself? Well let me just read to you, I know we've, last time I think I did this same thing to you, but I think that basically, um, Daniel Priestley wrote Key Person Influence, and he's huge on this, he thinks that you should be able to essentially sell yourself in a sentence or two,
 I'm a principal AI engineer app on me, as well as a security researcher who specializes,  in AppSec and AI. And then, like, his thing recommends that it's like one paragraph. So I put, I've helped Fortune 500 companies find vulnerabilities that could have cost,  them millions, and I've submitted over 1,000 vulnerability reports across Hack1 and BugCrab.Absolutely. 
I've helped people secure the planet by building and breaking systems. Reach out if you'd like to know more. That's pretty solid. I mean, yeah, so I think that's good for my current industry, but I think that this is,  more all-encompassing. Bigger, yeah. Yeah, it's like bigger and more, yeah, life-related. I wonder if I can work in the brainstorming slash hype man idea. Like I love... Lifting people. Yeah, essentially helping people see their potential.
a life coach, I really do believe that, but I don't know if a lot of my ideas fall into,  that category of kind of life coachery. It's more of something I do just in my relationships,  with my friends, so maybe it's not. Because I feel like the content I put out is more,  about innovation. I feel like I have, it is the brainstorming, but I feel like the majority, I think the parts of my blog that I post that resonate the most are when I'm, like from,  the assumptions made. Like that to me is like a typical Joseph Becker post. It's like an.
idea I have that I think will better humanity or society in some way by putting an idea,  out there that's not been thought about before. And like probably one of my most famous posts,  or most highest utility posts is that unguessable IDORs are malign vulnerabilities. That thing,  has been referenced in like hundreds of reports for people that find UUID-based IDORs. And,  they use it as logic to reason with and to argue the,  point that it should be a valid vulnerability, and it just got added, actually added to the.
HackerOne policy guide. They now recommend companies do accept unguessable ID IDORs just,  at a lower severity. Like the complexity, for CBSS, attack complexity would be high,  instead of low, or they should just, or they can just dock it down by instead of it being,  like a medium, it would be a low, or instead of a high, it would be a medium. Basically,  if by, if the, if someone had an oracle to get those IDs, let's say it would be a crit,  or a high, then you would downgrade it to a high or a medium, you know. And so I think,  like, if we can articulate that in a sentence, I think that's what I love doing with my brand.
Yeah. Okay, let's get a picture, you got a picture of this? Yeah, yeah, I'll take one,  more now that you've squared, close, fair, optimal, intelligent. Cool. Alright, you want,  to do the product idea? Which one? The, There was two, there was one was VC scouting of the service and then the one was innovation,  engine. And we were going to break that down into components. Which one are you more excited about? I am ultimately more excited about the engine, the idea engine.he, t
The other one is more tactical and more approachable, I would say. Okay, so let's do, actually I am going to put it in, discussion list. So the first one is innovation engine, and we still need to discuss, VC scouting, and.
VC scouting. The third thing I want you to do, I want to draw up here, threshold as a node in SPQA. Oh, this is the AI box by the way. This is the dual 4090s.
And I want to draw up here, threshold as a node in SPQA. Test test.
Test test,  test,  test,  test,  test,  test.  Oh, I've got problems. Oh, I've got problems.
Oh, I've got problems. Oh, I've got problems. Oh, I've got problems.
Hey, what's up? Hi. How are you? Did you call me by accident? No, I was facetiming you. Okay, sorry. I thought I actually spelled it out perfectly, but then it... Yeah, I'm sorry. My hair's crazy. No problem. I just looked down and I was like, oh, it's 3.15, which means it's 6.15 her time. I don't want to be too late to face time you guys. Oh, cool. Yeah. I'm glad you're still trying to go.
Me and Daniel are whiteboarding stuff. We already have like 15 ideas cooking, so. Hey! Yes. I think it can still kind of kill you, but then you just reappear again and you're fine.
Is it off? Yes. Here, say hi to Daniel. Sayla, say hi. Hi. Daniel's my friend I'm hanging out with today. Okay, what's your question? Yes. How do you light that to make a portal?
Sophia did that, but it didn't work. She decidedly just made one in the indoor space, and you put all the things in, but it won't light. I only played Minecraft today. We went on a walk with them, and then they got to play at their house and play Minecraft. And we got to see some pigs. Sayla, what are you doing? It doesn't work. What's that? What's up, buddy? I miss you and love you.
Oh, sweet buddy. Hey, Samuel, do you want to say hi to Daniel, my friend? Here, say hi. Hi. What's up? Now you're done. Okay. Where's Mia, hubby? What are you doing, baby girl? Don't drink it. That's gross.
Mia, can I have a kiss? What? Okay. Okay. I want to show you something. Look at this. Whoa, that's a huge flower. What do you think about it? I'll send a picture of it to you. Okay. There's a white button that shows the picture button. What do I do? Do I click it?
If you click that, it'll take a picture of me. Here, let me take it on my side, so I can take a picture of the flower. Okay. Here it is. I took it. Thank you. Send me a picture of it. Which one? This one? Yeah. Send it. Awesome. Do you love that? Yeah. And then? Okay, don't hold the bloom. It'll bloom when it's ready. I feel like yesterday, like today, this morning, it was like this. Yep. Then it was like this, like a couple of minutes later, and now it's like this! Okay, but it'll bloom.
Okay. All right. Hey, Celia, I love you. Dad, wait. I want to show you the giant plant. Last thing, okay? Okay. The herb garden, the flavor giant in it. Oh, the herbs are growing really well? It's growing so well. It's growing so well. Wow. Look. Yeah, they're huge. Look at the queso.
Tell mommy to cook with it. Mommy, cook with it. Oh, cool. Nice. I love how she's already been looking up in here all day. Yeah. Daniel was just telling me, they can't find queso at Mexican restaurants out here. So they love coming, like going back to the south where there's queso at every Mexican,  restaurant. Yeah. I told them that we go to the two near our house all the time. I think we heard that about the north as well. Yeah. Like in like Michigan and something.
Yeah. Cool. I'll call you later tonight. Thanks for calling in. Yeah, of course. I'll call you back tonight once they're in bed and stuff. Yeah. I'll call you back home at like 830 or 9. Just text me whenever you're back home. Yeah. All right. Love you. Good seeing you guys. Bye. Bye. I put these down and it actually hit me on the solutions and problems that like it just,  goes so well with Substrate, right? Like the Idea Generator has like cohesion with Substrate.
Yes. It really does because you can kind of explain anything with it. Okay so you, okay so Generator, the Selector is picking them, maybe. Well we talked about this. You definitely need some sort of way to prune ideas, especially if you're going to turn,  temperature up or use multiple models or something. So if you want to test whether or not these are going to work, you have to like experiment. Did you see this? There's been growth in this research area. People, there's a research paper about like testing psychology models or psychology potential.
solutions or something with agents, with simulated agents. Eventually this would hopefully be able to be done in like IRL, but the best problem,  space for us to test the Idea Generator is when we can actually do real experiments. So like computational-based experiments. Yeah. Like code or. or like the mathematical one or the logic one, it's like, did you get the answer. Yes. I wonder if you could find... Math would be the best possible, where it's like, this is.
a proof that works. Right. But I'm not good enough to do that. You're right, and it has,  to actually be able to execute, which I guess you could give that to a tool, be kind of,  me. Okay, so here's the cool part. Problems goes here. Yeah, definitely, yeah. And then.  export is kind of looking at... Well, it's almost the output of the experiment, right? They validate whether it worked or not, in some sense. But they also could just look.
at solutions, especially for ones that can't be proven yet. Yeah, or inspiration, yeah. I wonder if this works for bug bounty. So basically in bug bounty when it comes to hackbots... This the paradigm that I wonder if we can apply to this,  Was that when whenever you're trying to apply a hack bot to hack something that there is often, you know, these are bugs,  But more valuable than that are leads.
So that's kind of what you're thinking here is like basically inspiration is kind of like leads,  Yeah, like it could be high utility,  Even if there's no solutions because they're often going to be leads or inspiration that leads to solutions, right? Well in the case of bug bounty though, it'll also be weird weirdness.  Expected, you know 312 bytes and this one was this response size was different, right? Right anomaly, right? Yeah.
Yeah, so I mean one thing that I thought was cool about the pricing I know I suggested this to you,  You probably remember it but in case you forgot is that like,  You can apply funds in the form of a non-profit to this. Oh yeah. Because like the idea generation and then the selector like,  and then even the experiment is all going to cost inference or compute,  and so basically you could make this a form of non-profit or donation base,  where it's like I want to donate a thousand dollars to trying to solve this,  one tiny problem in cancer research and so now it creates one thousand.
loops or ten thousand loops or whatever like part of the pricing is the funding. Yeah, it requires. Yeah, and some don't, right? Some are like free or whatever. Well, but it's still inference. Some are underfunded. Well, I was just thinking like even if you're running Claude to validate these,  idea outputs it still costs something because Opus isn't free, right? And my idea original to this was like I expected only one percent.
of ideas generated are going to be like potential real world solutions or something. right and so like you might have to generate a thousand to get a small,  subset of ideas it's worthy of going to so one potential form factor of this,  that's another thing we could potentially talk about is the research,  paper did I tell you about Kai's research paper generator he got bullied,  out of it yeah take it down yeah because they said it was too dangerous,  basically academics told him that it was too risky to have that in the world.
because people who were wanting to pass off a research paper as fake would use,  it to generate a fake paper and try to get published because like a few hours,  to write this program they could literally go write a single prompt they,  would generate research like the fact that his app in the world doesn't make,  it a lower barrier to entry like the tech is there to generate fake research,  papers like no focus can generate amazing papers or paper I mean that's,  the old argument against hacking right if you talk about this,  It's like the open source argument, yes, yes.
So anyways, yeah, so I think the form factors for this, actually yeah let's talk about that, we do need to talk about UX. So basically, this is only as good as a UX for the experts. If this is not seamless for experts to review, they're not going to go to it. Or if they're, oh, how can we incentivize? Let's talk, yeah, two things we need to talk about are UX and incentivization. Because if you can incentivize experts to go here, now all of a sudden, the whole thing.
just works. Because basically, how do you get this flywheel going? And the biggest thing is you need experts. And you need cost, right? But I mean, we could bootstrap it by giving it a few hundred dollars or a few thousand,  dollars, whatever. But you need incentives to keep experts there. It just hit me, one amazing incentive would be dissertation writers, graduates who need,  ideas. They would love to... This,  is.
the end of the video. And honestly, the seeds idea kind of correlates with our resonating idea list.
Like basically, if we had influencers like you and I or whatever, who are willing to,  submit our ideas for our own industries that we're actually experts in, into the system. Yeah. Like, it uses that as kind of the inspiration, and then it's going to really increase the,  output. Like if we had Kai Gershocke give his suggestions for solving prompt injection, the output of,  ideas for prompt injection would be way better than if he didn't have his ideas.
Similarly, like if you put in your ideas of how to increase human flourishing, now all,  of a sudden the idea generator is going to like have really great elaborations on that. Yep. Yeah. The one thing I... What I like about the dissertation slash graduate paper term paper thing is because it forces,  them to go do the research about like finding out if this technique is like a known thing.
out there in some other research paper or if it's like a new idea, right, because like,  we're not going to know that about 99% of industries, but we are going to know that,  about cybersecurity or whatever else, but. You know the other thing that's a service that's needed is a really good description,  of the current state of the art. Yes. I mean I thought about this. Actually, so, you know on our notes for SRF, actually this could be an entire project, but basically I think we need, oh I tweeted this, yes, I can show you now because I had.
a thought recently. You might have even saw it. I said we need people who...
So, humans have this internal flowchart of like, especially like Sam Curry, when he's,  trying to exploit a secondary path reversal into a secondary context to exploit an API. He has an internal flow of like, oh, I'm going to try this, if I see this, that means this, and then I'm going to try this. But if that doesn't work, then I'm going to try this other thing. We have to capture that for every history, and then all of a sudden this thing just goes,  on fire. It takes off, right? It's like we need capture of the internal monologue of humans, and there's not really.
that very commonly in the literature or on websites. It's like you need those blog posts where it's like... Ooh, some of those do exist for hacking. I tried this, it didn't work. I tried this, it didn't work. I tried this, it didn't work. Dude, look at this.
Expert monologue context. I like it. Or capture. Ooh, yes. That's what we need. So, you should put this into our note document. Like, right now that was an idea that came off of your residence. You need to capture it so you can blog about it. We need a central repository in both of our labs where all of our ideas go. We do, yeah. We absolutely do. Like a shared doc or something. Yeah, I'm saying it doesn't have to be shared for us, but I mean, that would also be really cool. But I'm just saying, like, I think that we need to reduce the friction in our own lives.
So when we're in that resident state and we have ideas, it needs to be like, there's one thing we always do. Like I always go to this thing. I don't do this now, I'm just saying, but like you always open that. Or you always type something. Or you have a phone number you just text, it's like Twilio based. You just text the idea to it. You probably have this though. I do, I do. For me it's Apple Notes. I'm at 3,600 notes. So it's like, I never let anything stop. I never let it sit in my brain.
So this right here, that is super money. Because this, we need a repo for this. This becomes almost like a,  fabric use case or something. It's like a... Okay, so let's use the first case. Yeah, it can be abstracted out. It's like, hey, here's how humans reason about something in a very intelligent way, right?
Um... It's almost like a stream of consciousness, random... Yes, yes. It's literally a transcript of, like, what you just said. What's going on in the brain. Right. Yeah, and it's going to be the same of, oh, uh, fucking Stephen King talking about how I sit down and write an idea for a new character. Yes. Right, so... And there's just a capture of those, and it's like, author name, task that they're doing.
Right. So, Sam Curry, How I Think About API Attacks. This module feeds... It honestly feeds actions. I was thinking seeds. Because if this seeds, then feeds into the ideas generator. Yeah, it pairs with problems. Honestly, even if it's not perfect, it would probably still be useful.
Imagine someone suggested a problem, and it does rag or something to figure out the most likely relevant EMC. Yep. Then it would just say, hey, this EMC may not be directly relevant to this problem, but here's how experts think about a similar problem. Use that in your idea generation context. Yes. You know what I mean? Yes. It's like just a way to think about tangential problems. If you had enough for enough domains, even if, like, like Xampre's API attack would probably still super increase the idea generator, even if you're talking about XSS, right?
But it's still a hacker's approach to a problem. But, yeah, I also think that it doesn't just impact seeds. I also think it... It's the perfect context for every action. So basically, don't look at what you're about to say, but I still want to talk about this. So basically in your SPQA, or in your McCarthy note idea, these are all of the actions that.
people take in a company. You just want EMC for each of these. It's the first way to solve these actions. You've got to get EMC. You take the person who's doing that job now, and you make them EMC. As businesses, you want all of your employees to EMC all their actions. That's brilliant. Yeah, because that's the best way to get the agent to do the thing that you need them to,  do. Because they're going to follow that flowchart, right? Call for EMC. There you go. I like that. It's funny, because the EMC is also an analogy.
It's a recursive. Oh nice. Yeah yeah. Yeah because GNU is also. Oh it is? Yeah yeah. So call CFE and then E is yeah so,  but to your point so dude you could you remember I was talking about the structure of like any,  problem can be broken into the components? Yeah. So for that you basically say we need,  legitimate EMCs to be submitted. We have zero or we have nine or whatever. Right. But we're.
doing a call for EMC on this structure right here. That structure might be.  yeah. For a hackbot all of those components are bones or whatever. You know who actually,  can turn it out probably? Who? Because they're blind. KPMG and Accenture. Like all the actions,  that their consultants take. They can they can automate all their consultants away by,  just having them do EMCs for all of their tasks.
So, this is too high a level for this, but if we broke this, hmm. A problem can be solved by a bunch of actions. A pipeline. Could this recommend actions to solve problems? Pipeline. So this is the McCarthy thing. This is a pipeline which is a potential solution.
So a pipeline would be boom connects to boom connects to boom. This is a branch, if then, and then boom is the answer. So are you viewing this as like Sam Curry's EMC there? Well, or the FSD, full self-driving. This is the whole mechanism of full self-driving. This is a proposed pipeline. pipeline, what is the problem? FSD. Oh yeah, yeah, like drive a car without crashing. Get,  person A to B without crashing. Right. Well, let's say somebody has the idea in their mind.
It's a CFE for a pipeline. So we're calling for EMCs. EMC. And we need them for a pipeline. For a pipeline. Correct. So we basically say, hey, here's a proposal, actually that would,  be more like a CFP, call for a pipeline. Because they could look at this one and say, here's,  how I would do it, and that would be a monologue. Or they could be like, I don't like this one. Yeah, I was going to say, for lots of problems, you're not going to know what the pipeline.
is. Like for full self-driving, you won't know what the pipeline is. Well, no, no, it's,  a proposal. But you would submit pipelines as potential solution. Right. Although, maybe,  the pipeline... pipelines would just be listed in the solutions. Because all solutions are proposed- Are potential, right, they're all potential, yeah. Do you think solutions should be pipelines of actions?
There's so many objects. It is, it really, yeah, you have these like embedded. It's almost like solutions become PLs, and,  then the PLs list out to the pipeline object. I mean, I think there will be multiple ways to do that. Yeah. We don't want to get too bogged down, but. Yeah. But it's clear how these are all gonna link to each other and,  feed off of each other. And the fact that this all lives in a fucking GitHub.
So in plain text. That's true, that's really cool. I do think that the EMC idea is similar to the assistance, or sorry, assumptions made. Like this is something that is not obvious to everyone. but that is drastically going to help the system, like the AI agent ecosystem at large, that I think is really powerful. So put assumptions up there, as a circle, and then how it points to the different objects. Oh yeah, I'd love that.
I'm trying to figure out how it connects before I write it down. Yeah, so I think, well let's talk through it. So an assumption, it's almost like an... It's a part of the problem, right? It is, it's part of the problem. Because solutions are only going to work, like... Oh, you know what? It's actually part of a... It's almost like part of a frame while thinking of a problem. Well I just think that like, some problems are too big to solve with a single solution, or a single pipeline. So you constrain it by giving it assumptions.
You know what I mean? Assuming you are in America, then full self-driving works because of this... Assuming you are in America, then full self-driving works because of this... You know like the FSD as a problem is only solvable with this pipeline if you're in America,  because of the lights and the signs and the whatever. So the assumption is you're in America, the assumption is there's lines on the road, right? If there's lines on the road and you're in America, now this pipeline works. Yeah, yeah, yeah, yeah. And like maybe the assumption for the SAMQRI API attack is that it's HTTP 2.
Right. We don't talk about that because the HTTP 3 actually is going to be different and so,  then it won't work anymore or whatever, right? I love that. You know what I love about that is because it works for the Einstein thing too because,  a big part of like when you go from Newtonian physics to relativity, you're discarding assumptions. Right. You're like, well, what if it's not like that at all? Right. There's probably different theories depending on whether you believe in the multiverse or not, right?
Once you define state of the art thinking for any current problem, you can run extract,  assumptions on the state of the art thinking. And maybe you could challenge the assumption? And that's a list of things that might not be true about that new belief.
So for example, if you're like, problem, exploring galaxy, things are too far apart, assumption, speed of light. You can't tell if that's true or not. That assumption may not be true, we don't know. Exactly. So, similarly, let's say a teenage girl is for some reason using our system, and it's,  It's like Katie hates me, and how can I fix my relationship with her? It's like assumptions that you're making.
You're assuming she hates you, based on the behavior you've seen. You're assuming that being in her clique is required for happiness. Right. That's a huge one. Yeah. What assumptions are you... Yeah. It's almost like, what assumptions am I making, would be a powerful fabric pattern. Yeah. Absolutely. Because, like, someone may be able to put in the thoughts they're having, or the article,  they're writing, or whatever. Actually, that would be a good subcategory of critique my blog, or critique my thoughts.
You know, like, it would list things you said that are true or untrue, or whatever, but,  then it could be, like, the assumptions you're making. And so then, as the writer, if you did not want to make some of those assumptions, then,  you could change it. Yep. Anyways, yeah, I think, honestly, this could be a product. I don t know how you extract that from people s brains. Maybe you pay them to fill something.
out like you like offer surveys. We could run like ads. Like are you an expert in this? Can you prove it? If they can prove it then they do a survey where they like talk through,  like you can even have an AI led like when you re running a report for your when you,  re doing let s just use it for hacking. So like when you re hacking and you re trying,  to find an SSRF, what s the first thing you try? You know, what s it? Okay. And then the,  AI just goes in a loop. If that doesn t work, what do you try? If that doesn t work, what,  do you try? And then what s an example of success? And it gives an example of success. Okay. If you get that success, what do you do after that? How do you validate that it.
actually was true? You know, it s a whole bunch of leading questions and then you ve,  teased out an EMC. And then you pay them five bucks and then you go to the next industry. Or can we find a way to do it for free by line? Or so you stay inside. the industry and like, you hit UF plus like everyone in that bug bounty forum, now there's,  19 of those, and then the LM summarizes them, and pulls like the best, finds the overlap. I really like the idea, I bet Elvis could have a workflow output from a group of EMCs.
Yeah, sorry, go ahead. Well, so one thing that's a little bit of a risk here, a big reason people want EMCs inside of,  internal companies is not in a way that would transfer elsewhere. Because they're like, here,  at this company, we do it this way. Yeah, this is the way it's always been done. And what people,  don't realize is that department is not actually the one in power. Sure. However, there, but I,  think that just means you can use it for your company, though. Like, I think basically, you're.
saying page spinoff, can use EMCs as a part of your workflow. proprietary internal EMC. Yes, but I think EMCs for,  general,  for,  not prostate,  for substrate,  for substrate is still super valuable. Yeah, totally. I think it's just proprietary versus public. Yeah, public versus private EMCs, yeah. That's good shit. Jim.
That's why we gotta talk more. I know, seriously. And this is why we need to be financially,  where we can do this fucking once a week. Right, all the time, yeah, exactly. No, no, no, no. You're thinking too small. You're right, once a month. No, no, no. This is why we need to be,  completely financially independent and so rich,  that we can just say, okay, now go build this team. Like, me and you can have these ideas,  and we just hand it to the team and say,  this could be two products. Go make this GitHub and make it work well.
and go find a way to,  distribute that.
paid by VCs. Billions of dollars for all these attorney drill products. Think Tank is a service. Actually, that's really funny. A lot of the top hackers want to start hacking Think Tank. Cool. You want to pivot? Or go build? What do you want to do?
So, the Ideas Generator. Yeah, we didn't get into the nitty-gritty of how this is actually built. I mean, the first version of that is actually super easy. Right. You just ask Opus to do it. You literally just take a set of problems and turn off the temperature, some seeds, and just be like, go crazy. Yeah, the prompts do get fairly... Dude, have I showed you Instructor yet? I'm not sure.
This may affect how you think all this stuff should be built. So, Instructor is useinstructor.com. Oh, sorry. I think you're on. Open your phone up. Are you on there? Yeah.
So, basically, UseInstructor is Pydantic++. Okay. So, you can just instantiate a class, and then give Instructor the ability to patch,  the OpenAI client, such that when you do create, you pass it a response model, like UserInfo, and it fills out those fields in your Python, so you're not doing any regex, any parsing, any anything. It's so powerful. So, let me show you what I built with it. I'm so tired of my blog, let me show you one of my blog files, and you're going to be like,
yeah, that's dumb, and I'll be like, yeah, you're probably right, but I just want to,  show you. I'm unwilling to change it at this point. So, when I have a blog post, it looks like this. It has a title, a layout, categories, it's a Jekyll base, GitHub pages, you've probably,  had a blog like this in the past, or at least seen it. Yep. I always have like a header image. Yep. And then it's all marked down, and at the bottom, I have to fill out all my freaking,  metadata.
I don't have to like expect it to be wrong or anything. So then it generates the file name and it passes in the title and then the current date,  and time. Because like I said, the file name has to be the current date. So file name, again, it's all using this Pydantic++ called the instructor. And so here, for example, the file name is just a string. So then inside my file name prompt, it says, your job is to create the file name for a,  blog post. It will be the data, the file name will be the data followed by the name that you didn't.
mark down. So example, then I get a one-shot. Sorry. I'll show you. And then it generates the header. Okay, the header is actually annoying because the header is, the header is all of this crap. And it's dynamic because sometimes it's different categories, sometimes it's different stuff. So the header is a response model. This is where it gets complicated where you don't think it's cool. A header is both a category, which is another class, which is a string, and a tag, which,  is a list. So, I'm going to go ahead and click on this, and I'm going to click on this, and I'm going.
to click on this, and I'm going to click on this, and I'm going to click on this, and,  this, and I'm going to click on this, and I'm going to click on this, and I'm going,  In order for LLM applications to be extremely accurate and good, we need them to have similar.
internal monologue or the idea of the process for the hard task as a part of the context. So I propose a new way to do that with what is called EMC Expert Monologue Capture.
Elaborate on this. So python3blogger.py. So what's cool is, what's cool is I do this in the repo on my local machine,  so the files are there. I can just get add and get commit and then it's all live. Nice. So I'll show you, hopefully it doesn't get an error. Every once in a while it will error.
out whenever it's trying to download the file or sometimes it will fail like a pydantic.  validation. It will sometimes fail a pydantic validation because I'm using, for certain,  parts of it, actually I can show you here. So one thing that's cool is on each of these,  they use different models. So like this one uses sonnet, but this one uses opus, but there's.
one that uses haiku. Just for like price variability and stuff. So I think it takes about one minute to run it all, because it writes the blog, then it,  goes and generates the metadata, then it generates the title, then it generates the image, then,  it downloads the image from OpenAI, because it's using Dalai Lama 3, and then it puts,  it in the right folder, so that it's... Do I still have Jekyll running? Yeah, so I can actually see when the file gets written here, and it will automatically,  update on my localhost.
So there, now it's got the file, now it downloaded it, and now it's uploading. Unlocking LLM potential with expert monologues. This is using my custom writing style, I'll just read it. I've never heard this, but we'll see how it goes. Dude, this is really good. Look at that first sentence.
And it sounds very natural to me usually. So this is good. Dude, these are actually really, those four points are actually pretty good. Yeah, but the why behind complex decision making. More accurate nuance out this. Oh, Anna hates explainability. Dude, this is seriously good. So anyways, yeah, I knew you'd be stoked about that. This is basically what you told me to build a year ago,
and it's just like I was too lazy to actually do it. And then whenever I had instructor, it makes the barrier to entry so much lower because I don't have to parse it out and then copy and paste it,  and do string replaces on like, oh, it has a comma, I need a string to replace it, or quotes or whatever. That's super sick. So then I can just get add and get commit, and it has the photo, and it has the blog.
I don't know if there's a lot to elaborate on there, but basically I thought it would,  be cool if at some point in the future, maybe you think about it more, maybe you don't, but in the McCarthy map and in our lives, basically I think it would be cool, well yeah,  I think I mentioned that this morning because I think in all of our heads, AI unlocks basically,  almost infinite potential and the vision is clear in our brain and other people's I think,
but the clearer we can make it and the more we can articulate it, the more.
people who are accelerationists are saying is like, let's pull the time forward. And so when I think whenever we're able to have a clear vision before everyone else, we're pulling that future into the now. Yeah. So anyways, what I, um, the reason why I brought up clarifying the sub components of like SBQA,  and even in the security industry specifically is because I think it helps us have a more,  crystal clear vision. Yeah. Yeah. I agree. And this is one thing that VCs care about. Like when I've been talking with John Calgill and the other CEOs with these companies like,  this last week, it was like, they.
they don't know how it's going to shake out. And even today, it's really kind of confusing. Like,  ASM is very conflated. ASM means different things to people. Like Nestas is ASM, but it doesn't,  compare with Asset Note. Shows that Asset Note is insane. Guess what? He does no distribution. They literally don't advertise. They let their blog and their technical research be their,  advertiser, which they've succeeded that way. But to me, I want everyone to know about them, because they're doing it right. And so anyways, as I think about that, the industry is fragmented, like basically our nodes, our circles, our actions are a whole bunch of Gartner categories. And I.
want to know what the AI cybersecurity Gartner categories are going to be. That's what I wanted,  to clarify with you. But I think even grander than that, you have this vision of how digital,  systems are going to connect our lives and connect organizations. And I think within,  your vision of the future for humans and orgs in the S of the SPQA. So, the A threshold is the content node of S. And so, it would be really interesting.
for us to brainstorm what other nodes could be, because they're basically products. Yeah. Right? And the A is basically products. The P, the P is like really just what's in the world, but capturing all the P's is also,  a product. Yeah. And so, it's like, if we could have a really clear vision of like what all these products,  are, we would have a million ideas for upcoming founders, or even features at existing companies. And also, we would be able to tell VCs what to look for.
Like, hey, there's no doubt we're going to need a content SPA node, SPQA node, because,  everyone knows there's too much content, right? Like a digital assistant to help with that is like obviously a use case. But like there's so many non-obvious use cases that we haven't even found, but that humans,  will find through discoverability. And it'd be really cool if we could kind of lay those out. Mm. Mm. Okay, so that was what this was. And then the data sets. I think that there's just room,  for a product there. But mostly because like, yeah, let's get my logic. I don't know where.
this comes in. Maybe the steps in the solution or something. Basically, my logic, my idea,  is my claim of claims, my claims for this being a really good service is that we know,  synthetic data, synthetic data works. Right? The camera. Right, camera. Yeah, like, it's,  clear that a bunch of fine-tuned and trained models today are trained just on GPT-4 data. It at least helps you catch up. And then we also know that a lot of model providers and,  models do want to catch up. And maybe this is an egregious claim, but this is actually.
something that we could discuss, but people debate whether or not it's worth having domain,  specific models. Or do you just need a grand model that you then just give a... a system prompt of. I kind of have been falling in the latter, but it's hard to say. I'm definitely on the big model side. Well, I mean, I guess, yeah, if you needed, or I've seen people at least claim on Twitter,  that it's much better to have a model that's fine-tuned to output in JSON mode than it.
is to have one that's not. So if you took GPT-4 and fine-tuned it to output only JSON, it would still be as smart as GPT-4, or almost as smart, but it would output more consistent,  JSON, and that that's a good use case. So if you fine-tune a model to be better at tool,  calling, it often can be. I don't know what that means, though. Doesn't that just mean,  JSON mode? Right, exactly. All it just means is structured output, right? And even if it's not now, that will be the case soon. I just feel like they're wasting,  cycles. Yeah, I definitely still am very bearish on fine-tunes in general. I think there's 1%
of the time you need to fine-tune something, you usually just don't. You just need a better,  prompt. Better prompt. Yeah. Or more examples, which is still just a better prompt. If you give Haiku a bunch of Opus-generated few-shot examples, it performs like 99% as,  well as Opus in similar tasks. So you don't need to go find a model, you just need to use a big, smart model to generate,  your use cases and then use those as few shots and then use a cheap model like Haiku or Local,  or whatever. So yeah.
I don't know. I don't know if you're tired, if you want to do a podcast or if you want to do building, what are you filling energy for? Yeah. I don't feel like I could do a podcast anymore. I feel like we've captured so much. Yeah. Or you want to see what we can go data mine out of the recording? That's going to have so much good shit. Oh my God. That's going to have so much good stuff. We could do the VC scouting components. Okay. Yeah. That's good. Can we take a picture of this? Yeah.
Yeah. Yeah, I think this one.
Alright, so the idea for this one again was how they can vet companies. Yeah, basically VCScouting is already an industry because... They lack technical expertise. Guess what LLMs have? Big technical expertise. And then they often lack context, right? Like, you know, what products in the space do currently.
And I think top LLMs probably know that if they've been trained recently. Like if you asked any state-of-the-art model what Splunk does, it's going to know, right? Are there any companies you know the name of that have launched in the last year? In what? Actually, I'm just saying anything. I guess I'll test it with anyone.
Dropzone? What does Dropzone AI do? Yeah, I was going to do this with the same page for a sales pitch.
to help the company itself do the sales pitch. Yeah, like, hey, here's the people in the space. Here's how we differentiate, stuff like that. So basically have them babble, because they won't have a good story at all. Right. And then put it through the same page prompts. It turns it into an amazing marketing. Right, includes like differentiators, stuff like that.
Yeah, you've shown me, yeah, with the slider, and I also ended up subscribing. Oh, nice. So I've been in there, yeah. Oh, you've been in there? Yeah. Nice. Okay, analysis of the unique thing that they offer. You've got to get that Discord going, though. For what? The Discord scraping. Oh, yeah, yeah. Yeah, I need to write that down. It's such a huge enhancement on the thresholds. Oh, you know what's super sick about that?
An idea extractor out of the Discord. People don't even know they're mentioning good ideas, and this would be able to see them. Yeah, that gets a little gross, though, I think. Depends on... Depends on if you have attribution built in. If you have attribution built in, or permission. Yeah, true, from the Discord, yeah. Yeah. If they think they're just talking into the wind, like maybe it's okay. But I wouldn't want someone running that on UL. On UL. Right. Right. So- But that's like by it's very nature, private and subscription only, right?
Yeah. So you would definitely not give consent. But like for a public Discord, like, you know, mid-journey Discord. Mid-journey. So I was going to say, any of these AI projects, they're all public. Right. And they're just blabbing. And I truly believe that those are an assumption of- Right. People wouldn't say it in there if it wasn't like basically a, what's it called? Market square. Maybe that's the rule. Is it public or not? Yeah. And the channels have to be public too. It's like the Discord's public and also the channels are open to the public.
Yeah. Then you can try to go, you know. Okay. So this is exactly how I would do it. So you could do like a personality slash success analysis of the founders. Just you do everything, right? You would just look- everything about them. You would look at their LinkedIn, you would look at their like, do,  you want to level that out? You basically pull, you would, you would mine them for data. Hopefully they have a unique name. Well, yeah, well, yeah, but, but the question is, what,  is the pattern? The pattern is, what are the chances that this person will be a successful.
founder? Maybe, maybe you have that question last till the end. Like maybe that's the final,  question, but you just want all the context. Like you would say more things like, what,  are indicators of this person's work ethic? What are indicators? Well, yeah, I mean, that's,  all streaming in. Okay, gotcha. That's all, you collect as much as possible, but, but,  then this person gets a, you know, a score. Okay. And then all of these things keep going,  to the score and that's going to go out to them. Yeah, that's fair. Okay. So current.
state of the space is like, and that kind of goes with this one, which is what's going,  on in IAM. Yeah. Is there any innovation in it? What's the market cap, maybe? Who are the big leaders? Why are they still leaders? What are the problems that everyone's trying to solve right now? Then we capture the product itself. What are they claiming the product is, and how good it is, and how does it address those.
problems? Yeah. Because you might find a discrepancy there. Like, they're claiming the product is good. They're claiming the problem is lack of visibility, but their product actually doesn't give any,  extra visibility. You're right. Yeah. And then I would say... Contradictions would be an interesting thing. Yeah. Yeah. So, deception. Contradiction. Yeah. Analysis. And then we say, actual efficacy check.
Right. Maybe that would be put in by a human. Like, oh, these don't have a human. Yeah. We would have to do this ourselves, this part. Which is still good, that's still fine. We do the demo, all that. And then basically that folds up into... Do you think Jim and I will be able to process the demo? Because I've heard that it's really good at like... You can give it a video and ask when did this happen at the town stamp and stuff. I wonder if it would be good enough to give you a decent...
I think so. You know I'm not... It's the one model I'm not messing much with. I've only messed with a tiny bit. But I've heard it's really good at... Basically processing a long video for lots of context. Do you realize how much money Google is leaving on the fucking table,  by being a shit fucking UI company? It is so hard to get into AI studio and all that shit. In GCP it's impossible to spin up. You go into the interface and then you'll try to get back in it,  and you're on the wrong URL. You guys are so bad.
We are a GCP shop. I can never find the AI rag data stores every time I get in there. I have to go ask somebody how to get in. I search like a million different ways, I'm searching like rag data, data store, data,  space store. It never comes up. I can't find it in GCP. No, I mean, they just don't want to win. Right. Okay, so now we know the claims they're making about the problems. There's more substrate, but it's all the same shit.
Claims being made about how they're solving the problems, then we have basically a score,  that says how well are they solving those problems. And this is going to be a huge factor of that, like, does it actually work or not? How do we capture future potential? Because like a huge thing with startups is like, I mean, of course, it's going to be,  the founders, but like, is there, should we get like a roadmap, should we list like roadmap,  item or like potential for something? Like, I feel like there has to be something wrapped. up here it's like what is the potential either market or what's their do they have good vision.
like is there a road map to capture more of the market like do they have like a downstream,  plan I'm trying to think of the best way to word all that. Yeah I would say this would,  be a component here. Yeah vision. So that would be like the founder vision though. Right. Product vision. Yeah product vision great idea. Because like obviously their efficacy,  is not going to be gigantic at the beginning because it's just a POC. And product vision,  also points to the problems. Right. Because that's got to be a good story. And essentially.
these are being returned as line items going into a master prompt. Oh moat. It may be a,  sub prompt but you need at least a mention of moat. Yeah. Like what's their moat. Actually,  that's a fantastic question. Yeah. That can be it's online. What is their moat.
We need to clone ourselves so we can build all these products. Dude, seriously. I've often thought I wish I had a younger me to hire to do these things at a lower rate. I think about that all the time. I wish I could hire my brother to build this crap. You know what's sick about this? This entire product is 90% GUI and 80% this. Which of course adds up to more than 100. But this GUI right here, turning into a number of scores.
Where you just do filters for IAM, boom boom, 83, 19, blah blah blah. And then when you click on this one, it just expands out to the analysis of why they got that score. Alright. Here's the badass killer feature though. Okay. So, let's say we were going to all-in on this and drop everything else. We have to have a story that sells this product to VCs. You know what the story is? We ran it on previous investments. Here's how your X scored. Here's how PayPal scored.
Here's how Dropbox scored with our system. 100%. That's a killer feature for the data, right? Absolutely. You show them the history that proves, which obviously you can fake the data, of course, and they're going to say that's fine, but I still think that's actually a really great,  way to test the system over and over and over, is to take previous startups and their,  success or failure. Yes. Of course, it's going to be tainted. It's going to be in the training data. The LLM knows Dropbox succeeded, so it's going to maybe elevate it, but I think that'd be,  a really good way to test it, is with companies that you know failed or succeeded. Dude, you know what's funny about that?
What? So, I just met with my buddy. He was talking about this idea, which I did not think was so great, about helping bands,  find venues to play. Okay. Yeah. And he's like, oh, it could help make the band more popular. I'm like, no, dude, where it's at is picking who's going to be a successful band. So what I had, what I told him to do, and now he's going off to the team to do that,
probably be advisor for that, but I don't think anything's going to happen with it. But I told him all the interviews of all the successful bands. Right. What do you mean by interviews? So they're young? Oh, there's TV interviews with them. Yeah, TV interviews with like the Beatles. Right. And they're like, yeah, and I want to do this, and I'm going to take over the world, and blah, blah, blah, and I want to play this. And all I do is play my guitar, you know, 25 hours a day.
Right. And so I'm going to parcel those. Right. But do it for all the successful bands. And so the algorithm is printing the score. So it's the same thing you said. But then you interview upcoming bands. That's right. But you have an interviewer ask them questions. So it's a supervised version. Right. And their answers will indicate success or not based on how they answer the questions. Yes. Exactly what you said. What's interesting is I feel like this would definitely work.
You would never want to tell them though because it would taint their answers. This is what I think is really interesting about like YC interviews. Like if you notice Paul Graham and like other YC investors, Paul Graham and other YC investors,  talk about what they want founders to say in interviews. So then founders study that. I think about that all the time. I'm like, what are you telling people? Right. So anyways. Yeah. Yeah. He just revealed one. My goal is to not spend a cent of the money I raised. Right. Yeah.
They're all going to say that now. They're all going to be honest. They'll always say that. Right. But maybe that's to him a sign of disingenuity at that point. Right. Right. Right. Right. Right. Right. Yeah, so I think a snake oil version of this is super easy and super fast, but obviously,  we don't want to do that. Question is how quick can we get to something that's actually valuable?
Well, tell me this, does the snake oil version at least provide some value? Because I think that getting a POC, well maybe that's kind of giving away the idea, but I,  feel like even, so much of AI is obviously just augmenting humans, like even the snake,  oil vision, if it saves them half the time or gets them just a slight leg up on the research, I feel like observability in this is what would be massive. Like imagine if the LLM explains itself, and so imagine if John Calvula is like, well how.
did it give them a bad vision score? And you click in, and you go and you see under LinkedIn, their last three jobs they've only,  worked out one year, one year, one year. So, you know what I mean? And so, you need to ask them this question in the interview to try to get to the root.
of why. Now, that would be super valuable. So, now John calls them up and says, hey, we're considering investing in you. Do you mind explaining why you, you know, just like, you know, why did you leave the,  last couple of jobs you were at? If the person says, hey, it's because I really struggle with leadership. I just think I need to be the leader. But if the person kind of is wishy-washy and beats around the bush, you know, you nix it. You're not going to invest them at that point. And so, this might be actually a really great human in the loop system for, or like even,  the snake oil version of this may be very good for human in the loop based reasoning.
Yeah, sure. Yeah, maybe even like a suggested. I'll put it next steps interview right like these are the questions you need to drill,  them on based on what may or may not be true you know about them. I feel like stuff like this is so not that we have to put this but I do think people,  get hung up on like and I'm not saying you are on like the well this might be inaccurate,  my boss is at home and think about about the AI product stuff we're building and so we're.
taking way longer to release it compared to one right it's like there is no AI SAS security,  expert and yes it's not yes right now it currently can't handle queries to our database that,  return 500 rows it's like one we have no idea what the odds are of our customers asking,  questions that result in that output and two like I don't think they're going to judge,  us I actually think right now is the best time to release AI stuff as fast as you can,  because everyone's forgiving of it because they know the LLMs aren't perfect yeah in,  a year from now when everyone systems getting pretty tight not making as many.
mistakes. Your shitty system that makes mistakes is now going to be frowned upon. But right,  now is the perfect time to release it because if it's inaccurate it's okay. I think that's,  kind of the viewpoint I'm trying to have here is I think like, even if it's, things that,  are inaccurate can still be wildly helpful. But obviously if it ends up being accurate,  then it's like even better. You know what's helpful about this? What? Each line is a couple. That is so true. It's counter analysis. Right, so true. And it's like, we're like, look, this is startup analysis, but the first module is founder analysis. Right. Coming soon, state.
of the space. I was about to do this, right? It's a pipeline. Research the founder, research,  the space, research the thing, come up with a conclusion, and then it's even got some,  actions in it. The actions are write questions for the interview, write a summary, and do,  the research, and then it's like, okay, I'm going to do this, I'm going to do this, I'm,  going to do this, I'm going to do this, I'm going to do this, I'm going to do this, I'm,  going to do this, I'm going to do this, I'm going to do this, I'm going to do this, I'm,  It's all the same stuff over and over again. Dude, you have to know that like.
a visiting alien, we pitch this to them and they're like,  everyone's figured this out. Right. The whole,  universe is SPQA. Yeah, we've met like 900,000,  species and they all figured out components. And we all use LLM to communicate because,  when you get above a trillion parameters they can speak any new language. And so we just, they all. And they're all hybrids. They're either all AI or they're AI.
with some biological components just as like a throwback. As a consciousness or whatever, yeah. This is a good idea though. . I really love the mode analysis, because I feel like we could build that in two hours. Like you just need a LLM with a browser, and you need to tell it something like, hey generate.
ten search queries that are relevant to this space, if there's a Gartner Quadrant, make,  sure you use those keywords, and then tell me the names of the companies in the space, and then on the next follow-up you say, for these companies, go tell me what their claimed,  products do, and then you come back and you say, the idea for my company is that it has,  this, and it does these things different than those, give me a mode analysis for how likely.
it is to be displaced.
I don't have to hang out here all day, I know you have a lot of fun. I don't have to hang out here all day, I know you have a lot of fun. I don't have to hang out here all day, I know you have a lot of fun.
I think I need to go to that thing. It's 4.30. It's time for us to leave. We should go. Dude, this was so productive. Yeah, ridiculous. Alright, we're going to stop this. Hopefully it... I don't know.

TASK: you are a novel idea extractor. extract 10 novel ideas about ai OR security OR both from the data below. do not come up with your own ideas but you can elaborate on our ideas in the abstract or summary for each idea
